{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "packed-cinema",
      "metadata": {
        "id": "packed-cinema"
      },
      "source": [
        "# Real-Time Sentiment Analysis Task using Spark for English comments in Twitter "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "restricted-rocket",
      "metadata": {
        "id": "restricted-rocket"
      },
      "source": [
        "this notenook contains :-\n",
        "\n",
        "1- Data Analysis\n",
        "\n",
        "2- Data Cleaning & NLP Processing\n",
        "\n",
        "3- NLP Pipeline and ML Model Training & Tesing with accuracy about 78% \n",
        "\n",
        "4- (Extra! )Pipeline Evaluation on Real-Life Conversations & Rotten Tomatoes Reviews \n",
        "\n",
        "5- Real-time Streaming Sentiment Analysis on Real Tweets tracked on different keywords like Egypt, Usa, happy, sad , feeling and so on \n",
        "\n",
        "6- Deployment(Bonus Part) , Wep App is implemented to take a keyword and show table consisting of streamed tweers with it's corresponding sentiment prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "unlikely-check",
      "metadata": {
        "id": "unlikely-check"
      },
      "source": [
        "# 1- Import necessary packages "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "blocked-combination",
      "metadata": {
        "id": "blocked-combination"
      },
      "outputs": [],
      "source": [
        " import pyspark\n",
        "from pyspark.sql.functions import * \n",
        "from pyspark.sql.types import * \n",
        "\n",
        "from pyspark.sql import SparkSession \n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import re \n",
        "from pyspark.ml.feature import HashingTF, IDF, StringIndexer, SQLTransformer,IndexToString,CountVectorizer \n",
        "\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml import Pipeline ,PipelineModel #Build a pipeline\n",
        "\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator \n",
        "\n",
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp import DocumentAssembler\n",
        "\n",
        "\n",
        "import os\n",
        "import gc\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "anticipated-flexibility",
      "metadata": {
        "id": "anticipated-flexibility"
      },
      "source": [
        "lets start the session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "overall-alaska",
      "metadata": {
        "id": "overall-alaska"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession #Import the spark session\n",
        "from pyspark import SparkContext #Create a spark context\n",
        "from pyspark.sql import SQLContext #Create an SQL context\n",
        "\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Spark NLP\")\\\n",
        "    .master(\"local[*]\")\\\n",
        "    .config(\"spark.executor.memory\", \"12g\").config(\"spark.driver.memory\", \"12g\")\\\n",
        "    .config(\"spark.memory.offHeap.enabled\",True).config(\"spark.memory.offHeap.size\",\"16g\")\\\n",
        "    .config('spark.executor.cores', '3').config('spark.cores.max', '3')\\\n",
        "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
        "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
        "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.2.3\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acoustic-banner",
      "metadata": {
        "id": "acoustic-banner"
      },
      "source": [
        "# 2- Data Analysis and Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "according-preservation",
      "metadata": {
        "id": "according-preservation"
      },
      "source": [
        "please note that the file of the training won't be included in the submitted folder due to submission size \n",
        "\n",
        "the dataset used :https://www.kaggle.com/kazanova/sentiment140?select=training.1600000.processed.noemoticon.csv "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mediterranean-ceramic",
      "metadata": {
        "id": "mediterranean-ceramic"
      },
      "outputs": [],
      "source": [
        "training_data = spark.read.csv(os.getcwd()+\"/training_data.csv\", inferSchema = True, header = False) #Read in the data\n",
        "#training_data.show(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "extra-batch",
      "metadata": {
        "id": "extra-batch"
      },
      "outputs": [],
      "source": [
        "columns = [\"target\", \"id\", \"date\", \"flag\", \"user\", \"tweet\"]  \n",
        "\n",
        "training_data = training_data.select(col(\"_c0\").alias(columns[0]), col(\"_c1\").alias(columns[1]), col(\"_c2\").alias(columns[2]),\n",
        "                      col(\"_c3\").alias(columns[3]), col(\"_c4\").alias(columns[4]), col(\"_c5\").alias(columns[5]))\n",
        "#training_data.show(10) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "altered-myanmar",
      "metadata": {
        "id": "altered-myanmar"
      },
      "source": [
        "No need for ids , data , flag and user data for  our target analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "built-standard",
      "metadata": {
        "id": "built-standard"
      },
      "outputs": [],
      "source": [
        "training_data = training_data.select('target' ,'tweet')\n",
        "#training_data.show(10) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "demographic-bhutan",
      "metadata": {
        "id": "demographic-bhutan"
      },
      "source": [
        "let's process our data ! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "herbal-pottery",
      "metadata": {
        "id": "herbal-pottery",
        "outputId": "5202a1d3-f528-46fc-d3cd-9ddc360be5ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|target|tweet|\n",
            "+------+-----+\n",
            "|     0|    0|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in training_data.columns]).show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "earned-debate",
      "metadata": {
        "id": "earned-debate"
      },
      "source": [
        "we have no empyt data , so no need for imputation :)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sapphire-alert",
      "metadata": {
        "id": "sapphire-alert"
      },
      "source": [
        "let's check out target values distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mobile-charter",
      "metadata": {
        "id": "mobile-charter",
        "outputId": "a8831e0c-6ed9-48ab-d04a-cba9e55f2cf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------+\n",
            "|target| count|\n",
            "+------+------+\n",
            "|     0|800000|\n",
            "|     4|800000|\n",
            "+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_data.groupBy(\"target\").count().orderBy(\"count\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "external-router",
      "metadata": {
        "id": "external-router"
      },
      "source": [
        "No neutral values !! "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "broken-worry",
      "metadata": {
        "id": "broken-worry"
      },
      "source": [
        "Standarize our target values into 0s and 1s "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "transsexual-locking",
      "metadata": {
        "id": "transsexual-locking",
        "outputId": "55abe8cb-2681-4f12-e074-0e4ace5de024"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------+\n",
            "|target| count|\n",
            "+------+------+\n",
            "|     1|800000|\n",
            "|     0|800000|\n",
            "+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_data = training_data.withColumn(\"target\", when(training_data[\"target\"] == 4, 1).otherwise(training_data[\"target\"]))\n",
        "training_data.groupBy(\"target\").count().orderBy(\"count\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exposed-record",
      "metadata": {
        "id": "exposed-record"
      },
      "source": [
        "# The assumption here.. There's no neutral values \n",
        "\n",
        "# 1 => postive (Happy)  & 0 => negative (Sad)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "consecutive-edward",
      "metadata": {
        "id": "consecutive-edward"
      },
      "source": [
        "let's know more about the nature of our tweets data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "respected-shape",
      "metadata": {
        "id": "respected-shape",
        "outputId": "8a09a71e-b04e-4f7d-ed45-2112946c20fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------+\n",
            "|tweet                                                                                                                |\n",
            "+---------------------------------------------------------------------------------------------------------------------+\n",
            "|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  |\n",
            "|is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!      |\n",
            "|@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                            |\n",
            "|my whole body feels itchy and like its on fire                                                                       |\n",
            "|@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.       |\n",
            "|@Kwesidei not the whole crew                                                                                         |\n",
            "|Need a hug                                                                                                           |\n",
            "|@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?                  |\n",
            "|@Tatiana_K nope they didn't have it                                                                                  |\n",
            "|@twittera que me muera ?                                                                                             |\n",
            "|spring break in plain city... it's snowing                                                                           |\n",
            "|I just re-pierced my ears                                                                                            |\n",
            "|@caregiving I couldn't bear to watch it.  And I thought the UA loss was embarrassing . . . . .                       |\n",
            "|@octolinz16 It it counts, idk why I did either. you never talk to me anymore                                         |\n",
            "|@smarrison i would've been the first, but i didn't have a gun.    not really though, zac snyder's just a doucheclown.|\n",
            "|@iamjazzyfizzle I wish I got to watch it with you!! I miss you and @iamlilnicki  how was the premiere?!              |\n",
            "|Hollis' death scene will hurt me severely to watch on film  wry is directors cut not out now?                        |\n",
            "|about to file taxes                                                                                                  |\n",
            "|@LettyA ahh ive always wanted to see rent  love the soundtrack!!                                                     |\n",
            "|@FakerPattyPattz Oh dear. Were you drinking out of the forgotten table drinks?                                       |\n",
            "+---------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_data.select(\"tweet\").show(20,truncate= False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "final-joshua",
      "metadata": {
        "id": "final-joshua"
      },
      "source": [
        "# Tweets need to be more cleans..\n",
        "\n",
        "mentions , links , hashtags and HTML elements .. have to be removed from our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "informal-industry",
      "metadata": {
        "id": "informal-industry",
        "outputId": "174c5040-e02a-447a-fdb6-cec3de00b069"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1600000"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "annoying-taiwan",
      "metadata": {
        "id": "annoying-taiwan"
      },
      "outputs": [],
      "source": [
        "\n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', r'http\\S+', '')) \n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', '@\\w+', '')) \n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', '#', ''))\n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', 'RT', ''))\n",
        "\n",
        "\n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', '&amp;', ''))\n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', '&quot;', ''))\n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', '&gt;', ''))\n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', '&lt;', ''))\n",
        "\n",
        "\n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', '-', ''))\n",
        "\n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', '   ', ' '))\n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', '  ', ' '))\n",
        "\n",
        "\n",
        "training_data = training_data.filter((training_data.tweet!= ' ') &(training_data.tweet!= '')& (training_data.tweet!= '   '))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "accessible-burst",
      "metadata": {
        "id": "accessible-burst",
        "outputId": "209b813b-ea64-4919-8359-903f31e40135"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1597182"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "written-montgomery",
      "metadata": {
        "id": "written-montgomery",
        "outputId": "9d90190b-4156-4b9f-dc3a-53e76120e5cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------+\n",
            "|target| count|\n",
            "+------+------+\n",
            "|     0|798491|\n",
            "|     1|798691|\n",
            "+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_data.groupBy(\"target\").count().orderBy(\"count\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "favorite-thickness",
      "metadata": {
        "id": "favorite-thickness"
      },
      "source": [
        "Now we can split randomly our training data into train and test set "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "finnish-bundle",
      "metadata": {
        "id": "finnish-bundle"
      },
      "outputs": [],
      "source": [
        "Train_Test_sets = training_data.randomSplit([0.75, 0.25])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "institutional-durham",
      "metadata": {
        "id": "institutional-durham"
      },
      "outputs": [],
      "source": [
        "train_set = Train_Test_sets[0] \n",
        "test_set = Train_Test_sets[1] \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "duplicate-sheet",
      "metadata": {
        "id": "duplicate-sheet",
        "outputId": "d10c16aa-da40-4d91-bae8-654f753630d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "|tweet                                                                                                         |\n",
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "| Awww, that's a bummer. You shoulda got David Carr of Third Day to do it. ;D                                  |\n",
            "|is upset that he can't update his Facebook by texting it... and might cry as a result School today also. Blah!|\n",
            "| I dived many times for the ball. Managed to save 50% The rest go out of bounds                               |\n",
            "|my whole body feels itchy and like its on fire                                                                |\n",
            "| no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.                |\n",
            "| not the whole crew                                                                                           |\n",
            "|Need a hug                                                                                                    |\n",
            "| hey long time no see! Yes.. Rains a bit ,only a bit LOL , I'm fine thanks , how's you ?                      |\n",
            "| nope they didn't have it                                                                                     |\n",
            "| que me muera ?                                                                                               |\n",
            "|spring break in plain city... it's snowing                                                                    |\n",
            "|I just repierced my ears                                                                                      |\n",
            "| I couldn't bear to watch it. And I thought the UA loss was embarrassing . . . . .                            |\n",
            "| It it counts, idk why I did either. you never talk to me anymore                                             |\n",
            "| i would've been the first, but i didn't have a gun. not really though, zac snyder's just a doucheclown.      |\n",
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 15 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_data.select(\"tweet\").show(15,truncate= False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cheap-attempt",
      "metadata": {
        "id": "cheap-attempt"
      },
      "source": [
        "The data is more clean now"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "intensive-salvation",
      "metadata": {
        "id": "intensive-salvation"
      },
      "source": [
        "# 3- Pipeline and Training SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "contrary-ivory",
      "metadata": {
        "id": "contrary-ivory"
      },
      "source": [
        "The pipeline based on sparkNLP annotators and it consits of 10 stages "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "contemporary-montana",
      "metadata": {
        "id": "contemporary-montana"
      },
      "source": [
        "# 3-a Turn tweets into documents (Document Assembler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "directed-winning",
      "metadata": {
        "id": "directed-winning"
      },
      "source": [
        "this is a basic step to start work with sparkNLP annotators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "charged-samba",
      "metadata": {
        "id": "charged-samba"
      },
      "outputs": [],
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"tweet\") \\\n",
        "    .setOutputCol(\"document\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "extra-asset",
      "metadata": {
        "id": "extra-asset"
      },
      "source": [
        "# 3-b Create sentences from documents (Sentences Detector )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "infinite-relation",
      "metadata": {
        "id": "infinite-relation"
      },
      "outputs": [],
      "source": [
        "dentence_detector = SentenceDetector() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"sentence\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "scientific-theology",
      "metadata": {
        "id": "scientific-theology"
      },
      "source": [
        "# 3-c Turn these sentences into tokens (Tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "brown-development",
      "metadata": {
        "id": "brown-development"
      },
      "source": [
        "in this stage, sentences are split into words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "operating-million",
      "metadata": {
        "id": "operating-million"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer() \\\n",
        "  .setInputCols([\"sentence\"]) \\\n",
        "  .setOutputCol(\"token\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beneficial-desperate",
      "metadata": {
        "id": "beneficial-desperate"
      },
      "source": [
        "# 3-d Remove stop words from tokens (Stop Words Cleaner)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "crazy-township",
      "metadata": {
        "id": "crazy-township"
      },
      "source": [
        "stop words like I, you, me and so on are removed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "reserved-virtue",
      "metadata": {
        "id": "reserved-virtue"
      },
      "outputs": [],
      "source": [
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"token\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exceptional-hometown",
      "metadata": {
        "id": "exceptional-hometown"
      },
      "source": [
        "# 3- e,f Remove punctautions and turn the documented_tokens into array of tokens (Normalizer , Finisher)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "considerable-florence",
      "metadata": {
        "id": "considerable-florence"
      },
      "outputs": [],
      "source": [
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"cleanTokens\"]) \\\n",
        "    .setOutputCol(\"normalized\")\\\n",
        "    .setLowercase(True)\n",
        "\n",
        "finisher = Finisher() \\\n",
        "    .setInputCols([\"normalized\"]) \\\n",
        "    .setOutputCols([\"token_features\"]) \\\n",
        "    .setOutputAsArray(True) \\\n",
        "    .setCleanAnnotations(False)# To generate Term Frequency\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "published-officer",
      "metadata": {
        "id": "published-officer"
      },
      "source": [
        "# 3-g Hashing the tokens (hashingTF or Vectorization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "drawn-following",
      "metadata": {
        "id": "drawn-following"
      },
      "outputs": [],
      "source": [
        "hashingTF = HashingTF(inputCol=\"token_features\", outputCol=\"rawFeatures\")# To generate Inverse Document Frequency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "informal-reunion",
      "metadata": {
        "id": "informal-reunion"
      },
      "outputs": [],
      "source": [
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rental-perception",
      "metadata": {
        "id": "rental-perception"
      },
      "source": [
        "# 3-h Classification based on the hashed tokens using Suppor Vector Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "diverse-metabolism",
      "metadata": {
        "id": "diverse-metabolism"
      },
      "source": [
        "Our problem is a binary classification one. We could use many classifier based on ML like SVM , XGBoost ,Decision tree, Random Forest\n",
        "\n",
        "and we can use DNN to get a higher accuracy. But due to ram space and time constraints \n",
        "\n",
        "I had to choose a ML-approach which is the SVM. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imposed-county",
      "metadata": {
        "id": "imposed-county"
      },
      "outputs": [],
      "source": [
        "SVC = LinearSVC(labelCol = \"target\", featuresCol=\"features\",maxIter=13, regParam=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aging-uncle",
      "metadata": {
        "id": "aging-uncle"
      },
      "source": [
        "let's create the promising Pipeline "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "surrounded-touch",
      "metadata": {
        "id": "surrounded-touch"
      },
      "outputs": [],
      "source": [
        "nlp_pipeline = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            dentence_detector,\n",
        "            tokenizer,\n",
        "            stopwords_cleaner,\n",
        "            normalizer,\n",
        "            finisher,\n",
        "            hashingTF,\n",
        "            idf,\n",
        "            SVC])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "clear-waters",
      "metadata": {
        "id": "clear-waters",
        "outputId": "ec6f1224-b1dd-45d2-97e1-7caa9675a036"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finally Done !!!!\n"
          ]
        }
      ],
      "source": [
        "pipeline_model = nlp_pipeline.fit(train_set)\n",
        "print(\"Training finally Done !!!!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adjacent-trademark",
      "metadata": {
        "id": "adjacent-trademark"
      },
      "source": [
        "# 4- Evaluation on training and testing tweets sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "distinct-spirit",
      "metadata": {
        "id": "distinct-spirit"
      },
      "outputs": [],
      "source": [
        "def evaluate(input_set):\n",
        "    results=pipeline_model.transform(input_set)\n",
        "    evaluator = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "    accuracy = evaluator.evaluate(results)\n",
        "    print(\"Accuracy = %g\" % (accuracy))\n",
        "    print(\"Error = %g \" % (1.0 - accuracy))\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "brown-belief",
      "metadata": {
        "id": "brown-belief"
      },
      "source": [
        "# THE ACCURACY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "painful-literature",
      "metadata": {
        "id": "painful-literature",
        "outputId": "f05df911-b6dc-4d65-f8c5-ac23f604a53c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.792393\n",
            "Error = 0.207607 \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7923931156785957"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "based-cemetery",
      "metadata": {
        "id": "based-cemetery",
        "outputId": "7005d471-f4ee-415d-adac-dde174dd79b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.771817\n",
            "Error = 0.228183 \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7718168384056234"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "insured-programming",
      "metadata": {
        "id": "insured-programming"
      },
      "outputs": [],
      "source": [
        "pipeline_model.save(\"/pipeline\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acting-physics",
      "metadata": {
        "id": "acting-physics"
      },
      "source": [
        "After many trails and experiments , I could get a goot results which are around 79.2%  and 77.2% on train and test sets, respectively !!\n",
        "\n",
        "I considerd it an achievement, as the satate of art pipeline could achieve only about 80 % .\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "agreed-employment",
      "metadata": {
        "id": "agreed-employment"
      },
      "source": [
        "# **** TO RUN MY PIPELINE ****"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "laden-orbit",
      "metadata": {
        "id": "laden-orbit"
      },
      "source": [
        "Kindly import the neccesay packages and start a session as explained above ans resume execution from here instead of training the model yourself"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eleven-closing",
      "metadata": {
        "id": "eleven-closing"
      },
      "source": [
        "please make sure that you point to the correct pipeline path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "printable-elite",
      "metadata": {
        "id": "printable-elite"
      },
      "outputs": [],
      "source": [
        "pipeline_model=PipelineModel.load(\"/pipeline\")\n",
        "\n",
        "def predict(line): # function to make a predection on a tweet or line and outout happy or sad\n",
        "    sample_df = spark.createDataFrame([[str(line)]]).toDF('tweet')\n",
        "    #-- preprocessing---\n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', r'http\\S+', '')) \n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', '@\\w+', '')) \n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', '#', ''))\n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', 'RT', ''))\n",
        "\n",
        "\n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', '&amp;', ''))\n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', '&quot;', ''))\n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', '&gt;', ''))\n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', '&lt;', ''))\n",
        "\n",
        "\n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', '-', ''))\n",
        "\n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', '   ', ' '))\n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', '  ', ' '))\n",
        "\n",
        "    \n",
        "    #---\n",
        "    \n",
        "    result = pipeline_model.transform(sample_df)\n",
        "    sentiment = result.select('prediction').first()[0]\n",
        "    if(sentiment == 1):\n",
        "        sentiment = \"Happy\"\n",
        "        print (str(line)+ \" =====> \"+\"HAPPY\")\n",
        "    else:\n",
        "        sentiment = \"Sad\"\n",
        "        print(str(line)+ \" =====> \"+\"HAPPY\")\n",
        "\n",
        "    return line , sentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "brown-german",
      "metadata": {
        "id": "brown-german"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "flying-thanksgiving",
      "metadata": {
        "id": "flying-thanksgiving"
      },
      "source": [
        "#on a Real-Life Conversations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "alternative-report",
      "metadata": {
        "id": "alternative-report",
        "outputId": "5625c3d2-cd32-45c1-f386-6f7508e0ecdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iam really happy right now. =====> HAPPY\n",
            "Easy Task!  =====> HAPPY\n",
            "I will be sad if not accepted =====> HAPPY\n",
            "I am alone =====> HAPPY\n",
            "My day was full of good events but at the end , a car hit me and broke my leg =====> HAPPY\n",
            "Death. =====> HAPPY\n",
            "I failed in my last exam =====> HAPPY\n",
            "my dad bought me a new car =====> HAPPY\n",
            "the new car my dad bought me was crashed :( =====> HAPPY\n",
            "I am nervous =====> HAPPY\n",
            "I helped many people today =====> HAPPY\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('I helped many people today', 'Happy')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(\"Iam really happy right now.\") # =>1\n",
        "predict(\"Easy Task! \")# =>1\n",
        "predict(\"I will be sad if not accepted\") #=>0\n",
        "predict(\"I am alone\")# =>0\n",
        "predict(\"My day was full of good events but at the end , a car hit me and broke my leg\")# =>0\n",
        "predict(\"Death.\") #=>0\n",
        "predict(\"I failed in my last exam\") #=>0\n",
        "predict(\"my dad bought me a new car\") #=>1\n",
        "predict(\"the new car my dad bought me was crashed :(\") #=>0\n",
        "predict(\"I am nervous\") #=>0\n",
        "predict(\"I helped many people today\") #=>1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "threatened-courtesy",
      "metadata": {
        "id": "threatened-courtesy"
      },
      "source": [
        "--\n",
        "\n",
        "All of them predicted correctly !! "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "micro-transsexual",
      "metadata": {
        "id": "micro-transsexual"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aggressive-official",
      "metadata": {
        "id": "aggressive-official"
      },
      "source": [
        "dataset: https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data\n",
        "\n",
        "\n",
        "I use the train_set only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "endangered-panic",
      "metadata": {
        "id": "endangered-panic"
      },
      "outputs": [],
      "source": [
        "rotten_set = spark.read.csv(os.getcwd()+\"/reviews.tsv\", sep=r'\\t', header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rough-graphics",
      "metadata": {
        "id": "rough-graphics",
        "outputId": "3f10d1f5-ed98-4ee0-c982-36fcb39a25b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+------+\n",
            "|               tweet|target|\n",
            "+--------------------+------+\n",
            "|A series of escap...|   0.0|\n",
            "|  good for the goose|   1.0|\n",
            "|                good|   1.0|\n",
            "|the gander , some...|   0.0|\n",
            "|              amuses|   1.0|\n",
            "|but none of which...|   0.0|\n",
            "|none of which amo...|   0.0|\n",
            "|This quiet , intr...|   1.0|\n",
            "|This quiet , intr...|   1.0|\n",
            "|quiet , introspec...|   1.0|\n",
            "+--------------------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rotten_set.show(10,truncate= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "focal-graphic",
      "metadata": {
        "id": "focal-graphic"
      },
      "outputs": [],
      "source": [
        "rotten_set = rotten_set.select('Phrase' ,'Sentiment')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "organic-niger",
      "metadata": {
        "id": "organic-niger",
        "outputId": "5168b5a2-0957-437b-8d31-62081870cb7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+-----+\n",
            "|Sentiment|count|\n",
            "+---------+-----+\n",
            "|        0| 7072|\n",
            "|        4| 9206|\n",
            "|        1|27273|\n",
            "|        3|32927|\n",
            "|        2|79582|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rotten_set.groupBy(\"Sentiment\").count().orderBy(\"count\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mechanical-authentication",
      "metadata": {
        "id": "mechanical-authentication",
        "outputId": "e95c593f-b149-4714-a9c3-623341b1ef37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+-----+\n",
            "|Sentiment|count|\n",
            "+---------+-----+\n",
            "|        0|34345|\n",
            "|        1|42133|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rotten_set = rotten_set.withColumn(\"Sentiment\", when(rotten_set[\"Sentiment\"] ==1, 0).otherwise(rotten_set[\"Sentiment\"]))\n",
        "rotten_set = rotten_set.withColumn(\"Sentiment\", when(rotten_set[\"Sentiment\"] ==3, 4).otherwise(rotten_set[\"Sentiment\"]))\n",
        "rotten_set = rotten_set.withColumn(\"Sentiment\", when(rotten_set[\"Sentiment\"] ==4, 1).otherwise(rotten_set[\"Sentiment\"]))\n",
        "rotten_set = rotten_set.filter((rotten_set.Sentiment!= 2))\n",
        "rotten_set.groupBy(\"Sentiment\").count().orderBy(\"count\").show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "skilled-shopper",
      "metadata": {
        "tags": [],
        "id": "skilled-shopper"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import DoubleType\n",
        "rotten_set = rotten_set.select(col(\"Phrase\").alias(\"tweet\"), col(\"Sentiment\").alias(\"target\"))\n",
        "rotten_set = rotten_set.withColumn(\"target\", rotten_set.target.cast(DoubleType()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mexican-violation",
      "metadata": {
        "id": "mexican-violation",
        "outputId": "fbf1d94a-5b6a-42cb-c098-eb58ef86e86c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.674874\n",
            "Error = 0.325126 \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.6748738199220691"
            ]
          },
          "execution_count": 226,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(rotten_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "blank-ferry",
      "metadata": {
        "id": "blank-ferry"
      },
      "source": [
        "It's not a bad accuracy. However, the drop in accuracy happens to the difference between the nature of pipeline training data and this data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "responsible-bicycle",
      "metadata": {
        "id": "responsible-bicycle"
      },
      "source": [
        "# The Real-Time Streaming Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acknowledged-grace",
      "metadata": {
        "id": "acknowledged-grace"
      },
      "source": [
        "Now, real tweets is being streamed to be prediceted on my pipeline \n",
        "\n",
        "the tweets are tracked on different keywords like Egypt, Usa, happy, sad , feeling and so on \n",
        "\n",
        "every tweet is predicted individually in this form, tweet ====> sentiment prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "corresponding-anaheim",
      "metadata": {
        "id": "corresponding-anaheim"
      },
      "source": [
        "# Keywords = {happy,sad,feeling,sentiment}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "advanced-relationship",
      "metadata": {
        "id": "advanced-relationship",
        "outputId": "6530fe91-4fb6-4fe2-9820-eb3475506875"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "@FreeTrap2x Mfs don’t even know the definition of misogyny 😂😂sad =====> SAD\n",
            "(to the tune of The Devil Went Down To Georgia)\n",
            "\n",
            "🎶 Russell Greer went down to Vegas , he was lookin' for a whore to… https://t.co/r8Vfn5OH3J =====> SAD\n",
            "RT @BayouBun: Bow Wow came with the steel chair when he said puffy ain’t got a artist wit a milli and happy =====> HAPPY\n",
            "RT @MeganMorantWWE: I can’t wait for @YaOnlyLivvOnce vs @CarmellaWWE at #ExtremeRules 🙌 =====> HAPPY\n",
            "It’s real sadboi hours! Hit me with your best sad songs, doesn’t matter what genre. Classical, orchestral, rap, hip hop, doesn’t matter. =====> SAD\n",
            "RT @BTSupdate_7: Look at Jimin happily dancing and waving 😭😭😭🤗🤗\n",
            "\n",
            "They are really happy ~\n",
            "\n",
            " https://t.co/qe0Em4Z811 =====> HAPPY\n",
            "RT @DomainDoris: I’m not plotting mischief, I’m an innocent floof! Happy #Caturday pals! 🐾🥰🐾 #CatsOfTwitter #Cat #cats #pets #animals 💙 #Ca… =====> HAPPY\n",
            "RT @AlwaysRamCharan: Introducing #Siddha's Love #Neelambari ! \n",
            "Wishing you all a very Happy Ugadi.\n",
            "#Acharya\n",
            "@KChiruTweets @sivakoratala @he… =====> HAPPY\n",
            "RT @TrendsAjith: Happy to reveal the first year anniversary celebration tag for @KeralaAjithFC team ! \n",
            "\n",
            "TAG:  #1YrOfPrideKeralaAjithFC\n",
            "\n",
            "#Aj… =====> HAPPY\n",
            "He’s seen the sad tears only once before : an evening when the sun set low and the white hospital room walls were cast in orange. =====> SAD\n",
            "Mi mamita me contesto, im happy again =====> HAPPY\n",
            "Rossano Brazzi  #BOTD \n",
            "SUMMERTIME – David Lean, 1955 \n",
            "#cinematography: Jack Hildyard \n",
            "#costumes: Rosi Gori\n",
            "w/ Katha… https://t.co/UJmSFPvcS1 =====> HAPPY\n",
            "Gm y'all how we feeling? =====> SAD\n",
            "RT @Ienscap: Happy Birthday James Gandolfini\n",
            "\n",
            "Rest in peace legend. https://t.co/y7UtaEPCaG =====> HAPPY\n",
            "RT @lazarusfaIIing: happy birthday to the only character to ever exist!!! #13YearsOfCastiel https://t.co/k39QaDICer =====> HAPPY\n",
            "RT @ColorfulMen72: 🌸🍆🧔🏻🕳👦🏽 happy Saturday\n",
            "\n",
            "@dilf2050 @brotheragensbr  @themusculartime @JuanLovesCock @hot_connection2 @FrenchGaymer @BOKEP… =====> HAPPY\n",
            "RT @lovedsickgirls: lisa looked so sad when she got asked about variety shows. i hope she knows we appreciate all her efforts to put out co… =====> SAD\n",
            "RT @sakshijoshii: .@INCIndia doesn’t reward those who win elections for them \n",
            "\n",
            "Amidst a huge Modi wave, @capt_amarinder took back power fro… =====> SAD\n",
            "RT @linoscent: dori being almost as big as soonie and doongie now i'm sad https://t.co/E8TpEMXIxs =====> SAD\n",
            "RT @KBMcGee86: I'm a #Fansbury for the reason she's a wonderful human being an always appreciate that hard work pays off an even at her age… =====> HAPPY\n",
            "RT @mingeniusloverr: I’m so happy to see my beautiful man. We love you and miss you, Yoongi! Have a safe flight #SUGA  @BTS_twt 💙 \n",
            "\n",
            "PROUD O… =====> HAPPY\n",
            "@shujigives @shiepromotes happy 18th =====> HAPPY\n",
            "RT @taetaction: look how hobi is watching them i'm so sad https://t.co/bkOvououUd =====> SAD\n",
            "RT @imjadeja: Many happy returns of the day to our honourable PM @narendramodi ji.\n",
            "Wishing him the very best on his special day 🙏 =====> HAPPY\n",
            "@VIP_IDiKONIC The satisfaction on Chanwoo's face looking at June happy 🥺 =====> HAPPY\n",
            "RT @ddowouon: MY GORGEOUS LITTLE SISTER 😍 =====> HAPPY\n",
            "RT @AfcThrissur: Happy to Launch the 1 Year Anniversary Tag for @KeralaAjithFC. Kerala Ajith  Fans State Committee was formed 22 Years Ago.… =====> HAPPY\n",
            "RT @jakesimthings: Happy 1st Anniversary Jake from Enhypen. ❤ https://t.co/Uskgcj5HEr =====> HAPPY\n",
            "@Peachfront @TradingTaylor @DocMCohen This happens for everything actually. If someone gets shot near you and you f… https://t.co/FFHxCVB3Uv =====> SAD\n",
            "RT @bts_ot7_ly: @Namjo0onie Happy birthday ❤❤❤ =====> HAPPY\n",
            "SAD ENDING DONG =====> SAD\n",
            "RT @Trend_pages: Happy to Launch the 1 Year Anniversary Tag for @KeralaAjithFC. Kerala Ajith  Fans State Committee was formed 22 Years Ago.… =====> HAPPY\n",
            "RT @OnlineSuriyaFT: Happy Birthday #Vinay sir on behalf of Suriya anna fans 💓💐\n",
            "\n",
            "Waiting For #EtharkkumThunindhavan 😉✌🏻&amp; Best wishes for you… =====> HAPPY\n",
            "RT @hrjhops: why be sad when you have renjun\n",
            "https://t.co/gPjGpUWlBs =====> SAD\n",
            "RT @Olie_edwin: For the love of sports \n",
            "Happy birthday  our sports queen 👑 @CarolRadull \n",
            "Your impact on the world of sports is commendable.… =====> HAPPY\n",
            "Today Gakuran-kun is happy! He must be having a good day! :D https://t.co/FpEAUiZAkq =====> HAPPY\n",
            "RT @ACTORAJITH_FANS: Happy to reveal the first year anniversary celebration tag for @KeralaAjithFC team ! \n",
            "\n",
            "TAG:  #1YrOfPrideKeralaAjithFC… =====> HAPPY\n",
            "Still sick, im so sad, no stream again today.. Really want to stream but cant bc im sick. 🤒🙁 =====> SAD\n",
            "Sad hours  https://t.co/KbZG44CnsT =====> SAD\n",
            "RT @MoneydefiSwap: Together the future with MoneydefiSwap🚀🔥\n",
            "We are happy to announce that Trade $MSD is now available on Hotbit exchanges 🌬… =====> HAPPY\n",
            "@virginia_spotts Aahh happy birthday to you AND your skin! =====> HAPPY\n",
            "RT @XXL: Happy birthday, @xzibit! 🎉\n",
            "\n",
            "What’s your favorite song of his? https://t.co/qmV3LLIV8C =====> HAPPY\n",
            "RT @That_Lex: I’m doing it tired. I’m doing it sad. I’m doing it scared. Idgaf! I’m doing it. =====> SAD\n",
            "RT @saebits: happy 1 year to mr. heart thank u for giving us one of my fav couples ever &lt;3\n",
            "[ #LeeSeJin #CheonSeungHo #MrHeart #미스터하트 ] http… =====> HAPPY\n",
            "RT @official__INI: ▲▼━━━━━━━━━\n",
            "   #HAPPYTAKUMIDAY\n",
            " ━━━━━━━━━ ▲▼\n",
            "\n",
            "    HAPPY BIRTHDAY \n",
            "            TAKUMI\n",
            "           20210614\n",
            "\n",
            "#INI #アイエヌアイ… =====> HAPPY\n",
            "@buyabes_fatma Happy birthday Buyabis 😘🎈❤️ =====> HAPPY\n",
            "RT @dailyjimitonin: Look at our Jimin waving everyone!!\n",
            "He’s so kind! Happy Journey Jiminie, have a safe flight to New York !!! We love you… =====> HAPPY\n",
            "@elonmusk @SpaceX #PEC smart chain wishes you a Happy Mid Autumn Festival @V2Chain https://t.co/7zWL13kCpV =====> HAPPY\n",
            "RT @rameshlaus: Happy to Launch the 1 Year Anniversary Tag for @KeralaAjithFC. Kerala Ajith  Fans State Committee was formed 22 Years Ago.… =====> HAPPY\n",
            "@Trumpeteer14 I feel that way too.  \n",
            "I'm disturbed by the current sad situation in the USA &amp; the world but I don't… https://t.co/RDm0IWPkC0 =====> SAD\n",
            "@QueenLeora Happy birthdaaay!! 🎈🎈🎈🎉 =====> HAPPY\n",
            "RT @woniekook: heeseung: “jungwon always comes in my room and says good night with his killer smile”\n",
            "\n",
            "no because he’s been doing this since… =====> HAPPY\n",
            ".@hastyqt happy birthday boss😌 =====> HAPPY\n",
            "RT @iingwen: Wishing a happy Mid-Autumn Festival to all in #Taiwan &amp; across the world. Let’s keep working together to fight this pandemic,… =====> HAPPY\n",
            "@ArnoldLabour Hi Arnold, we are happy to help. Please follow our support page: [https://t.co/RyfgUDsGU8] so our Ube… https://t.co/Hv08e28hk1 =====> HAPPY\n",
            "RT @JorgeJimenezArt: Lately every day is Batman day for me, but still,:D  HAPPY BATMAN DAY, FRIENDS! #HappyBatmanDay #batman @tomeu_morey c… =====> HAPPY\n",
            "RT @httpsukkiee: HAPPY FIRST YEAR TO THIS MASTERPIECE🎉 @treasuremembers https://t.co/m9qqPRl3YB =====> HAPPY\n",
            "RT @lali_031827: im sad for lisa, it breaks my heart she deserves better💔 =====> SAD\n",
            "RT @exolyoutubeteam: EXO 엑소 'Don't fight the feeling' MV\n",
            "\n",
            "85,987,906 views\n",
            "\n",
            "86M coming later today, right? Have you streamed at least once… =====> HAPPY\n",
            "RT @GinoTorretta: Happy College Football Saturday!  Enjoy the games. https://t.co/jyK2CA3n5P =====> HAPPY\n",
            "RT @AlwaysRamCharan: I wish everyone a happy and prosperous year ahead...😊\n",
            "\n",
            "ఉగాది శుభాకాంక్షలు.\n",
            "#ಯುಗಾದಿ #GudiPadwa #नवसंवत्सर #தமிழ்ப்புத்… =====> HAPPY\n",
            "RT @aussieblair: Happy Friday everyone 🤘🏽 https://t.co/XXBvlCu6A9 =====> HAPPY\n",
            "RT @RanbirKUniverse: Happy Independence Day ❤\n",
            "\n",
            "Credit to uploader \n",
            "\n",
            "#RanbirKapoor https://t.co/6hYnSt01E5 =====> HAPPY\n",
            "Strange feeling prints. There seemed no reason to trust a man's faith in God meant\n",
            "\n",
            "✌️🎗️\n",
            "... &lt;&amp;lt;كٕوٍٓدٓ &gt;&gt;... \n",
            "NM… https://t.co/ikhXqa7g9p =====> HAPPY\n",
            "@lowlvldemon We are very sorry that this has happened with your order and would like to investigate this further fo… https://t.co/WV7dw0o3vZ =====> SAD\n",
            "RT @iingwen: Wishing a happy Mid-Autumn Festival to all in #Taiwan &amp; across the world. Let’s keep working together to fight this pandemic,… =====> HAPPY\n",
            "Happy to say that 2 of these films were used in my previous class hehe =====> HAPPY\n",
            "RT @TFC_mass: Happy to Launch the 1 Year Anniversary Tag for @KeralaAjithFC. All The Best Dear Team For All Your Future Works 😎 \n",
            "\n",
            "Tag 👉 #1Y… =====> HAPPY\n",
            "I hope and you have had a safe flight\n",
            "I love you very much, take care of yourselves a lot and be happy @BTS_twt 💜 =====> HAPPY\n",
            "RT @FOXYGIVES: $12 | ₱600 | 170.000 IDR\n",
            "\n",
            "- follow me 🔔\n",
            "- retweet + 60k\n",
            "\n",
            "Happy 60k everyone!🥳💗 =====> HAPPY\n",
            "RT @DivaYnwa: Morning Lovelies 🥰 \n",
            "\n",
            "Happy Matchday 🔴 https://t.co/aoRFi77KTY =====> HAPPY\n",
            "@Cable_Darker To being myself again and we ended on a happy note. We finished off our food and then we went our sep… https://t.co/M438Cad94i =====> SAD\n",
            "RT @BTSupdate_7: Look at Jimin happily dancing and waving 😭😭😭🤗🤗\n",
            "\n",
            "They are really happy ~\n",
            "\n",
            " https://t.co/qe0Em4Z811 =====> HAPPY\n",
            "RT @mahonsunto: feeling wavey 🌊✨ https://t.co/5GcSmPmUOr =====> SAD\n",
            "@neptufly halo ! good night 🧚🏻‍♀️ how are you today? 🌷 good 👍🏻 or bad 👎🏻 be happy yap 💓 i hope you have a nice slee… https://t.co/VSPxiREScS =====> HAPPY\n",
            "RT @btsarmy2018x: Look at Jimin dancing and waving, he looks so happy 😭 https://t.co/4lXLA02zK2 =====> HAPPY\n",
            "RT @sleafordmods: Anti vaxers. Will you be happy when everyone is dead ? Would you be happier with square wheels on your motor? =====> HAPPY\n",
            "One year ago. Happy gotcha day Georgiana! https://t.co/MN4D1PNBB4 =====> HAPPY\n",
            "Happy heavenly birthday Truman ❤️ https://t.co/xhySmx3oyR =====> HAPPY\n",
            "RT @kthpn: btw yall,, do not force taehyung to post something,, he will post when he wants to and when he fells more comfortable and we'll… =====> HAPPY\n",
            "RT @LisaMarieBoothe: This is so sad. There is no humanity anymore. So many monsters. =====> SAD\n",
            "@xxjisatsu @uzendayon Cry like a baby, sad to be you 🍼 =====> SAD\n",
            "@agustdeehee happy birthday luv 🥳🤍 =====> HAPPY\n",
            "Happy 1st Anniv😘💕 =====> HAPPY\n",
            "RT @GeethaArts: Wishing the 'Supreme Superstar @nimmaupendra' garu a very happy birthday, also we are extremely happy to have him as a part… =====> HAPPY\n",
            "RT @Chlozee2: .\n",
            "\n",
            "Hello thank you so much for the 25k followers, I'm so happy 😍😍😍\n",
            "\n",
            "https://t.co/OhP8CuEali https://t.co/OadOGQ9Xap =====> HAPPY\n",
            "RT @90sfootball: Happy Birthday Ronaldo! https://t.co/ikVvZQeLVt =====> HAPPY\n",
            "RT @Number10cat: Happy #Caturday\n",
            "https://t.co/m8CSwNx6Rv =====> HAPPY\n",
            "Hey Larv... look 4ward to it\n",
            "\n",
            "N all the f1r3 I will spit\n",
            "\n",
            "Will b non 4 prophit \n",
            "\n",
            "U WON'T TORTURE her majesty again… https://t.co/vO47ibvLiV =====> HAPPY\n",
            "@juanxkvui happy satnight gan =====> HAPPY\n",
            "RT @iksongsplaylist: really happy they gave us a sight of ikjun in specs for the last time 🥺 https://t.co/VKupbchtPX =====> HAPPY\n",
            "RT @GajrajCorps_IA: #AzadiKaAmritMahotsav\n",
            "#IDC2021\n",
            "\n",
            "HAPPY INDEPENDENCE DAY \n",
            "\n",
            "@PMOIndia\n",
            "@DefenceMinIndia\n",
            "@SpokespersonMoD\n",
            "@adgpi\n",
            "@easterncom… =====> HAPPY\n",
            "RT @renkiger_: “I’m a big fan of BTS. I think they’re also national heroes. I think it’s incredible. What they do for Korean ppl makes [me]… =====> HAPPY\n",
            "RT @Hoss21_: Happy Birthday to the coolest cat on twitter! @catturd2 https://t.co/APm0NyBp9X =====> HAPPY\n",
            "RT @HappypusNFT: Here is a unique Happypus collection inspired by Charles Hoskinson's own (Happy Octopus) mascot. \n",
            "\n",
            "#ADA #Cardano #NFT #CNF… =====> SAD\n",
            "RT @lali_031827: im sad for lisa, it breaks my heart she deserves better💔 =====> SAD\n",
            "RT @RebaToTheRescue: Happy Saturday, Friends! Reba hopes that you head on over to @kweliTV for some sensational stories that you're sure to… =====> HAPPY\n",
            "RT @jaekhoon: 25 pesos gcash giveaway bc JAKEHOON 😭 + im jus rlly happy today 😭\n",
            "\n",
            "rt + like\n",
            "no need to follow \n",
            "ends at 11pm!! 💥😭👍🏻 https://t… =====> HAPPY\n",
            "RT @itosoewandi: Andree Bienfait...\n",
            "@bgv_online @ampomata @paulbar59067209 @BrindusaB1  @mujahidgrw @AnnaCountessK @dianadep1 @DavLucia\n",
            "\n",
            "Pe… =====> SAD\n",
            "RT @_TWnostalgia: Happy SIVA SATURDAY fanmily! The butterflies butterflies have started in my tummy as it's literally just hit me that mond… =====> SAD\n",
            "RT @laurenkwinn: The Big Lie is alive and well in Pennsylvania and @JohnFetterman will be joining @mehdirhasan this morning on @VelshiMSNBC… =====> HAPPY\n",
            "RT @sungwonfolder: happy 1st anniversary to our seven amazing boys @ENHYPEN_members, thank you for bringing us along on your journey of gro… =====> HAPPY\n",
            "RT @tn_ajith: Here we go let's celebrate One year of team @KeralaAjithFc in Twitter. \n",
            "\n",
            "TAG 👉 #1YrOfPrideKeralaAjithFc\n",
            "\n",
            "Happy to share our p… =====> HAPPY\n",
            "For those fortunate students and tutors on @Pianolotmusic - and my  piano courses at Le Vert - this photo will brin… https://t.co/aXlJ7FgSV1 =====> HAPPY\n",
            "RT @TFC_mass: Happy to Launch the 1 Year Anniversary Tag for @KeralaAjithFC. All The Best Dear Team For All Your Future Works 😎 \n",
            "\n",
            "Tag 👉 #1Y… =====> HAPPY\n",
            "This is hilariously scary and sad. This statement alone. It is 2021 and they are still lost under the hood =====> SAD\n",
            "RT @yoonietangerine: it's so sad to know how you are all so active when it comes to some chismis but rarely hyping up about votings. please… =====> SAD\n",
            "To the boy who never got to grow up, the man who never really was, and the world’s greatest detective and superhero… https://t.co/S8PZ03q6Vu =====> SAD\n",
            "RT @brfootball: Happy 45th birthday to El Fenomeno 🇧🇷 \n",
            "\n",
            "He was 𝐝𝐢𝐟𝐟𝐞𝐫𝐞𝐧𝐭 ♨️\n",
            "(via @EuropaLeague)\n",
            "https://t.co/fz2QxFCDC6 =====> HAPPY\n",
            "RT @blckbsct: Happy Birthday @catturd2 hope it’s the best one yet!\n",
            "#CatturdsBirthday https://t.co/b3tFGvIG8E =====> HAPPY\n",
            "RT @EchoLake_NSFW: a girl always needs another pair of hands… even if they are just for feeling up this body\n",
            "\n",
            "rt’s appreciated, but not exp… =====> HAPPY\n",
            "@funder @Aqua174 What to do when sad and lonely? =====> SAD\n",
            "This is a big opportunity. Made by a very professional and experienced team. Without a doubt, This is one of the be… https://t.co/pbRAYzZVDQ =====> HAPPY\n",
            "RT @eye_kar: May God shower his choicest blessings on Eid. Wishing you a Happy Eid! #EidUlFitr https://t.co/T7YuCbU9o6 =====> HAPPY\n",
            "RT @muftimenk: The good and bad, happy and sad - these things will happen in your life. Try not to be upset, learn to take things in your s… =====> SAD\n",
            "RT @LexiReign_: Happy Friday everyone! Ready to relax and enjoy the weekend?😘 https://t.co/xwRlCUXddR =====> HAPPY\n",
            "RT @Funimation: Happy birthday to the incredible captain of the Black Bulls, Yami Sukehiro! ♣︎\n",
            "\n",
            "[via Black Clover] https://t.co/PzVV8dh0l1 =====> HAPPY\n",
            "RT @JacksonWGlobal_: [INFO] 210918\n",
            "\n",
            "#JacksonWang is on 2 different shows tonight, both airing at the same time, 20:20 Beijing Time 😆🥳\n",
            "\n",
            "1️⃣… =====> HAPPY\n",
            "Happy birthday, Cas. Oh my god, I miss you so much. This is making me sad but i know, you are still alive, in my he… https://t.co/oKL4jLaJbH =====> SAD\n",
            "RT @Jeanna350: Happy Freaking Friday!! 😁😄 Have a Fantastic Day! 💜 Be Kind 💜🤗 https://t.co/p2DSdGi8sw =====> HAPPY\n",
            "RT @popovmusic: I’m proud and happy to share our new single ANGEL in collaboration with legend @pauloakenfold OUT NOW on @interplayrec Stre… =====> HAPPY\n",
            "@catturd2 Happy birthday, Kitty-Kitty🥳 =====> HAPPY\n"
          ]
        }
      ],
      "source": [
        "import tweepy\n",
        "from tweepy import Stream\n",
        "from tweepy.streaming import StreamListener\n",
        "from tweepy import OAuthHandler\n",
        "import socket\n",
        "import json\n",
        "\n",
        "class TweetsListener(StreamListener):\n",
        "    \n",
        "    def on_data(self, data):\n",
        "        msg = json.loads(data)\n",
        "        try:\n",
        "            predict(msg['text'])\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "\n",
        "\n",
        "    def on_error(self, status):\n",
        "        print(status)\n",
        "        return True\n",
        "\n",
        "auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_secret)\n",
        "twitter_stream = Stream(auth, TweetsListener())\n",
        "twitter_stream.filter(track = [\"happy\",\"sad\",\"feeling\",\"sentiment\"], languages=[\"en\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "played-construction",
      "metadata": {
        "id": "played-construction"
      },
      "source": [
        "# Keywords = {Egypt,USA}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "civil-happiness",
      "metadata": {
        "id": "civil-happiness",
        "outputId": "09c63425-7b05-444f-a6e0-65ba706ea99c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RT @catturd2: 😂😂😂😂\n",
            "\n",
            "#CatturdsBirthday is the #2 trend in the USA =====> HAPPY\n",
            "RT @chapps: *Who* is this #handsome rogue? Wonderful details in the hair, and an appropriately Hadrianic beard for c. 125 AD. Sadly, a fune… =====> HAPPY\n",
            "RT @taehyungpic: 📸#TAEHYUNG  KR 🛫 USA\n",
            "\n",
            "have a safe flight ♡\n",
            "FASHION ICON V https://t.co/cbmOlpnkfc =====> HAPPY\n",
            "RT @taehyungpic: 📸#TAEHYUNG  KR 🛫 USA\n",
            "\n",
            "have a safe flight ♡\n",
            "FASHION ICON V https://t.co/cbmOlpnkfc =====> HAPPY\n",
            "RT @UFOMJLeader: #AncientAliens Just said the Pyramid Text describes the Extraterrestrial gods as coming from Sirius and Orion. The Dogon c… =====> HAPPY\n",
            "RT @TaehyungUSA: Taehyung Trends USA [NEW]\n",
            "\n",
            "● Baby Prince V | Entertainment \n",
            "\n",
            "Another cute nickname for FASHION ICON V given by the media h… =====> HAPPY\n",
            "@bwhite_ee @pugpolitics1 @MattBraynard One might even argue that an insurrection is an act of war against the USA a… https://t.co/janeh1DiQp =====> SAD\n",
            "I’d salute, blare “GOD BLESS THE USA”, all the decorum. A new holiday. A blending of 1776 &amp; 2021/2022/2023/2024. \n",
            "A… https://t.co/vKGXvEibxF =====> HAPPY\n",
            "RT @MollyJongFast: What if Facebook is a cancer just like big Tobacco? =====> HAPPY\n",
            "@nebegamonkai @MarkLevineNYC @RepRitchie @mvelaznyc Look @TTarasenkova\n",
            "Another USA dumb bot here 🙄🙄\n",
            "They spread fas… https://t.co/bHNfuyUSu1 =====> HAPPY\n",
            "@TreyYingst @ErinElmore More than 500,000 in the USA in less than a year.\n",
            "Due to ineptitude &amp; dismissiveness, becau… https://t.co/V7C5W8Po6p =====> SAD\n",
            "RT @JohnFetterman: “Pennsylvania wants this. Pennsylvania’s farmers need this. Pennsylvania’s veterans need this. Pennsylvanians that have… =====> SAD\n",
            "@TheEmilyDBaker @emme329 I’m not from USA so unfamiliar w/ laws… doesn’t invoking the 5A automatically tell us &amp; po… https://t.co/hG5hNaZb6V =====> SAD\n",
            "@derekmutuma @BoqorWiilBari @Malikbandz5 @MohamedAliUmar1 @citizentvkenya @YvonneOkwara U seem not to know ur own h… https://t.co/CuETVNOVjv =====> SAD\n",
            "RT @catturd2: 😂😂😂😂\n",
            "\n",
            "#CatturdsBirthday is the #2 trend in the USA =====> HAPPY\n",
            "RT @SAFoundationN: Highlights from #BuildingDreams #USAtour2021 where  #SAF reps @SAfridiOffical, @jk555squash &amp; @adnanactor along with #SA… =====> HAPPY\n",
            "RT @NunesAlt: Dems who want to win elections please pay attention to this. =====> SAD\n",
            "@WhiteHouse @POTUS @HHSGov @SecBecerra Open usa open up your borders  to eu and uk families coming back to there fa… https://t.co/diJcCK3NwZ =====> SAD\n",
            "RT @TrumpsBlonde_1: Over 10,000 Haitians entering Texas, USA in the last 2 days…\n",
            "\n",
            "how is this even possible?? https://t.co/2ocACpTVOs =====> SAD\n",
            "RT @accessmimi: Mariah Carey, Britney Spears, Selena Quintanilla, and Aaliyah are the ONLY artists this year to spend a week as the most-st… =====> HAPPY\n",
            "Real time #gold price in your National Currency For #Android\n",
            "\n",
            "https://t.co/eBZXaJvz50\n",
            "\n",
            "#USA #NewZealand #WhiteOut =====> HAPPY\n"
          ]
        }
      ],
      "source": [
        "import tweepy\n",
        "from tweepy import Stream\n",
        "from tweepy.streaming import StreamListener\n",
        "from tweepy import OAuthHandler\n",
        "import socket\n",
        "import json\n",
        "class TweetsListener(StreamListener):\n",
        "    def on_data(self, data):\n",
        "        msg = json.loads(data)\n",
        "        try:\n",
        "            predict(msg['text'])\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "\n",
        "\n",
        "    def on_error(self, status):\n",
        "        print(status)\n",
        "        return True\n",
        "\n",
        "auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_secret)\n",
        "twitter_stream = Stream(auth, TweetsListener())\n",
        "twitter_stream.filter(track = [\"egypt\",\"usa\"], languages=[\"en\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "russian-rochester",
      "metadata": {
        "id": "russian-rochester"
      },
      "source": [
        "# SIMPLE WEB APP (Bonus Part)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "union-world",
      "metadata": {
        "id": "union-world"
      },
      "outputs": [],
      "source": [
        "import tweepy\n",
        "from tweepy import Stream\n",
        "from tweepy.streaming import StreamListener\n",
        "from tweepy import OAuthHandler\n",
        "import socket\n",
        "import json\n",

        "class TweetsListener(StreamListener):\n",
        "    def on_data(self, data):\n",
        "        msg = json.loads(data)\n",
        "        try:\n",
        "            tweet,feeling = predict(msg['text'])\n",
        "            put_table([['tweet', 'sentiment'],[put_text(str(tweet)), put_text(str(feeling))]])\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "\n",
        "\n",
        "    def on_error(self, status):\n",
        "        print(status)\n",
        "        return True\n",
        "\n",
        "auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_secret)\n",
        "twitter_stream = Stream(auth, TweetsListener())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dominican-footage",
      "metadata": {
        "id": "dominican-footage",
        "outputId": "f8f26dcf-1dac-483b-bc88-909058850dc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "no one makes me happy like ateez does =====> HAPPY\n",
            "RT @LucasTurnbloom: HOW TO CAT: “Spot” \n",
            ".\n",
            "Happy #caturday everyone!\n",
            ".\n",
            "https://t.co/qG1IXo4wUe https://t.co/gPsbTYuxBE =====> HAPPY\n",
            "@TrustWallet Happy birthday trust wallet and twt thank you for the Best wallet =====> HAPPY\n",
            "RT @neiljedcastro: We all have our breaking points in this life. We all get tired of waiting and chasing for that dream to happen. We all g… =====> HAPPY\n",
            "♡                                                       ♡\n",
            "            put this on your profile\n",
            "            and who… https://t.co/QLE9chbD3x =====> HAPPY\n",
            "@tuechainz happy gday my boy 💪🏾 =====> HAPPY\n",
            "RT @Gatorcwboyfan: 5 ain’t it, bottom line. We all wanted his patience to be rewarded. Fairytales don’t always have a happy ending. =====> HAPPY\n",
            "RT @mygiorni: 🎶 Happy Birthday Laboon 🎶 \n",
            "\n",
            "#ONEPIECE https://t.co/RZ3OkPxvZP =====> HAPPY\n",
            "happy birthday to me im gonna eat king crab and drink g&amp;t’s all night =====> HAPPY\n",
            "RT @razzparks: happy birthday @JawnRocha, an amazing photographer plus more!\n",
            "from all of us to you, have a good one ❤️⭐️!! https://t.co/Pz1… =====> HAPPY\n",
            "RT @ChelseaFC: Happy Birthday, @cpulisic_10! 🥳 https://t.co/BG9tddm7M7 =====> HAPPY\n",
            "RT @_Pammy_DS_: I love people who are genuinely happy for other people's happiness. =====> HAPPY\n",
            "I don't often see these two specific Sonic shows merged together like this.\n",
            "\n",
            "Let's give it up for the characters fr… https://t.co/PF61fpnTVj =====> HAPPY\n",
            "Thank god most of these actual subhuman pieces of shit aren’t in this country. =====> HAPPY\n",
            "RT @aura_draws: Happy belated birthday to our favorite Mondstadt alchemist, Albedo! ✨🏔️🎂\n",
            "\n",
            "#GenshinImpact #原神 #Albedo #Klee https://t.co/eyF… =====> HAPPY\n",
            "RT @SkySportsPL: \"It's such a great feeling - words can't even explain it!\" 🤩\n",
            "\n",
            "Leon Bailey was very happy with his 20-minute cameo in #AVFC… =====> HAPPY\n",
            "RT @dagurlJT: One band one sound. 😌 =====> HAPPY\n",
            "RT @loey_exo7: Happy Birthday Papa Park! 🎊️\n",
            "\n",
            "#CHANYEOL #EXO https://t.co/ExX8wkxjyT =====> HAPPY\n",
            "RT @sane_kyle: Happy anniversary to @SupergiantGames' hit, Hades!\n",
            "Reposting this in celebration of this event! \n",
            "\n",
            "#hadesgame #zagreus #hades… =====> HAPPY\n",
            "RT @jayjayriv: happy hispanic heritage month https://t.co/4p1dNmUI8Z =====> HAPPY\n",
            "@piilliiii Happy birthday best girl 🤍🤍🤍🤍🤍🤍💗💗 =====> HAPPY\n",
            "Happy Birthday Castiel 💗 =====> HAPPY\n",
            "RT @DanSchkade: 🦇 @DialHForHagai and I pooled our resources (he wrote, I drew). Happy #BatmanDay to those who observe 🦇 https://t.co/6MipqB… =====> HAPPY\n",
            "@mfarrar13 Thanks for reaching out, Matt! We'd be happy to help you. Please DM us with the name. email and ZIP Code… https://t.co/BKGKToHS43 =====> HAPPY\n",
            "RT @marie_nassar: @semljnika Good morning dear Daria 🌹🍂☕️🍪🙋‍♀️😘\n",
            "Have a happy Monday and a wonderful new week full of joy and happiness my s… =====> HAPPY\n",
            "I didn't even consider that this many people would come to celebrate. To be fair I am a bit shocked, but I'm happy...♪ =====> HAPPY\n",
            "RT @ZackSnyder: Happy Batman Day! It's the perfect day to run out and grab your copy of the ZSJL. #BatmanDay #ZackSnydersJusticeLeague \n",
            "\n",
            "ht… =====> HAPPY\n",
            "Liam retweeted this tweet! =====> HAPPY\n",
            "Happy National Dance Day 2 some real QUEENS @EmmaSlaterDance @atrebunskaya @BrittBStewart @CherylBurke… https://t.co/vZRzWcc3kK =====> HAPPY\n",
            "RT @ZackSnyder: Happy Batman Day! It's the perfect day to run out and grab your copy of the ZSJL. #BatmanDay #ZackSnydersJusticeLeague \n",
            "\n",
            "ht… =====> HAPPY\n",
            "RT @ndoup9: When junior khanye speaks we think he's crazy,  I'm happy Royal AM humiliated Baxter and he must leave with immediate effects h… =====> HAPPY\n",
            "Omg yes, I did it in the morning. Lol. =====> HAPPY\n",
            "RT @taranooyen: This is the best example of parenting that I’ve ever read on Twitter. Parenting is wanting to make your child happy, make y… =====> HAPPY\n",
            "RT @rue29Napa: Who else loves @napafarmersmkt 🙋🏻‍♀️ So many new vendors at today’s Saturday market. Happy to see the Dahlia Farm from Petal… =====> HAPPY\n",
            "RT @ZackSnyder: Happy Batman Day! It's the perfect day to run out and grab your copy of the ZSJL. #BatmanDay #ZackSnydersJusticeLeague \n",
            "\n",
            "ht… =====> HAPPY\n",
            "RT @Scotkraut: If the last 5 years have been positive in any way, then it was to clearly demonstrate the difference between Scotland and En… =====> HAPPY\n",
            "RANBOO SOUNDS SO HAPPY IM GONNA CRY :((( /POS =====> HAPPY\n",
            "I have never seen a happier person who goes in search for how to be a happy human being #mondaythoughts #ThinkBIGSundayWithMarsha =====> HAPPY\n",
            "RT @_wowser: Happy birthday to @HannahTelle, our Max Caulfield ❤️ https://t.co/jo6xoEpERn =====> HAPPY\n",
            "im gonna rip my organs our he sounds so happy an d excited im gonan =====> HAPPY\n",
            "RT @TheOriginalCIR: me vs. animated me\n",
            "\n",
            "(happy #BIPOCvampday 🦇🩸) https://t.co/jHDPGF5PSr =====> HAPPY\n",
            "RT @Coolwednesdays_: Happy birthday Capone https://t.co/v6AONbG9z3 =====> HAPPY\n",
            "Lopes putting out classics every week!! 😭 Damn I’m happy for the boys. Lopes up we win! =====> HAPPY\n",
            "RT @tshirtsunited: While we're all laughing at Pep's comments on city fans, city fans in general and memes about free tickets to see city i… =====> HAPPY\n",
            "RT @kateschIoe: like he said 🤷🏽‍♀️ https://t.co/fvNy43Gkc4 =====> HAPPY\n",
            "RT @darkseidxflame: Happy #BatmanDay lets appreciate Ben Afflecks Batman https://t.co/qJa5D73YR6 =====> HAPPY\n",
            "@TheJimCornette @StaceyCornette Happy Birthday =====> HAPPY\n",
            "Please visit our website for details around our plan as we approach Sept 20th. We are happy to host those of you th… https://t.co/1awlP8AUNF =====> HAPPY\n",
            "Just Minted my First Ever #SolanaNFT 🔥🔥🔥. Listing soon on @SolanartNFT. I'm happy to be part of the @TheCavemenClub… https://t.co/ZHsgQegFhW =====> HAPPY\n",
            "RT @C_Angermayer: \"Ultimately, I believe that #mentalhealth has 100% total addressable market because 100% of the people want to be healthy… =====> HAPPY\n",
            "RT @C_Angermayer: \"Ultimately, I believe that #mentalhealth has 100% total addressable market because 100% of the people want to be healthy… =====> HAPPY\n",
            "RT @ZackSnyder: Happy Batman Day! It's the perfect day to run out and grab your copy of the ZSJL. #BatmanDay #ZackSnydersJusticeLeague \n",
            "\n",
            "ht… =====> HAPPY\n",
            "RT @ZackSnyder: Happy Batman Day! It's the perfect day to run out and grab your copy of the ZSJL. #BatmanDay #ZackSnydersJusticeLeague \n",
            "\n",
            "ht… =====> HAPPY\n",
            "RT @ZackSnyder: Happy Batman Day! It's the perfect day to run out and grab your copy of the ZSJL. #BatmanDay #ZackSnydersJusticeLeague \n",
            "\n",
            "ht… =====> HAPPY\n",
            "@GeminiFlanaganC @ChrisEvans @ChrisEvansmylov @ChristEvans81 @chrisevansrare @softchrisdodger @cap_evans_… https://t.co/LBWhkMOmuj =====> HAPPY\n",
            "RT @n1010505: Social media is a trick used by people to be happy and  also show others that they are happy.\n",
            "\n",
            "Everybody search for happiness… =====> HAPPY\n",
            "RT @Anitta: One year of \"Me Gusta\" and I'm so happy and proud of it ❤️ @iamcardib @MYKETOWERS https://t.co/j2opDnu05W =====> HAPPY\n",
            "RT @bumplebeee: ⚜️hii I’m sammie, I’m a black transmasc artist trying to make others happy with my art ٩( ᐛ )وI’m getting so close to hitti… =====> HAPPY\n",
            "RT @CynthiaNixon: Happy one year, my Mildred ❤️  #Ratched\n",
            "\n",
            "@MsSarahPaulson @MrRPMurphy @RatchedNetflix https://t.co/xlAGX0T1At =====> HAPPY\n",
            "lock it off this game is cancelled =====> HAPPY\n",
            "What a Saturday 😅 =====> HAPPY\n",
            "RT @DanScavino: Happy Birthday @catturd2! \n",
            "#CatturdsBirthday https://t.co/hNNyVVgIBo =====> HAPPY\n",
            "❝Nononononono Its fine...I'll get it under control okay! Just need another...note from my therapist or something❞… https://t.co/6jWAYkKsC2 =====> HAPPY\n"
          ]
        }
      ],
      "source": [
        "from pywebio.input import input, FLOAT\n",
        "from pywebio.output import put_text ,put_table \n",
        "def doit(word):\n",
        "    twitter_stream.filter(track = [str(word)], languages=[\"en\"])\n",
        "\n",
        "def bmi():\n",
        "    word = input(\"Enter one keyword: \")\n",
        "    doit(word)\n",
        "if __name__ == '__main__':\n",
        "    bmi()\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "skilled-bracket",
      "metadata": {
        "id": "skilled-bracket"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "great-stamp",
      "metadata": {
        "id": "great-stamp"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "name": "Script.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
