{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "packed-cinema",
      "metadata": {
        "id": "packed-cinema"
      },
      "source": [
        "# Real-Time Sentiment Analysis Task using Spark for English comments in Twitter "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "restricted-rocket",
      "metadata": {
        "id": "restricted-rocket"
      },
      "source": [
        "this notenook contains :-\n",
        "\n",
        "1- Data Analysis\n",
        "\n",
        "2- Data Cleaning & NLP Processing\n",
        "\n",
        "3- NLP Pipeline and ML Model Training & Tesing with accuracy about 78% \n",
        "\n",
        "4- (Extra! )Pipeline Evaluation on Real-Life Conversations & Rotten Tomatoes Reviews \n",
        "\n",
        "5- Real-time Streaming Sentiment Analysis on Real Tweets tracked on different keywords like Egypt, Usa, happy, sad , feeling and so on \n",
        "\n",
        "6- Deployment(Bonus Part) , Wep App is implemented to take a keyword and show table consisting of streamed tweers with it's corresponding sentiment prediction\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "unlikely-check",
      "metadata": {
        "id": "unlikely-check"
      },
      "source": [
        "# 1- Import necessary packages "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "blocked-combination",
      "metadata": {
        "id": "blocked-combination"
      },
      "outputs": [],
      "source": [
        " import pyspark\n",
        "from pyspark.sql.functions import * \n",
        "from pyspark.sql.types import * \n",
        "\n",
        "from pyspark.sql import SparkSession \n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "import re \n",
        "from pyspark.ml.feature import HashingTF, IDF, StringIndexer, SQLTransformer,IndexToString,CountVectorizer \n",
        "\n",
        "from pyspark.ml.classification import LinearSVC\n",
        "from pyspark.ml import Pipeline ,PipelineModel #Build a pipeline\n",
        "\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator \n",
        "\n",
        "import sparknlp\n",
        "from sparknlp.base import *\n",
        "from sparknlp.annotator import *\n",
        "from sparknlp import DocumentAssembler\n",
        "\n",
        "\n",
        "import os\n",
        "import gc\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "anticipated-flexibility",
      "metadata": {
        "id": "anticipated-flexibility"
      },
      "source": [
        "lets start the session"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "overall-alaska",
      "metadata": {
        "id": "overall-alaska"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession #Import the spark session\n",
        "from pyspark import SparkContext #Create a spark context\n",
        "from pyspark.sql import SQLContext #Create an SQL context\n",
        "\n",
        "import pyspark.sql.functions as F\n",
        "\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"Spark NLP\")\\\n",
        "    .master(\"local[*]\")\\\n",
        "    .config(\"spark.executor.memory\", \"12g\").config(\"spark.driver.memory\", \"12g\")\\\n",
        "    .config(\"spark.memory.offHeap.enabled\",True).config(\"spark.memory.offHeap.size\",\"16g\")\\\n",
        "    .config('spark.executor.cores', '3').config('spark.cores.max', '3')\\\n",
        "    .config(\"spark.driver.maxResultSize\", \"0\") \\\n",
        "    .config(\"spark.kryoserializer.buffer.max\", \"2000M\")\\\n",
        "    .config(\"spark.jars.packages\", \"com.johnsnowlabs.nlp:spark-nlp_2.12:3.2.3\").getOrCreate()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acoustic-banner",
      "metadata": {
        "id": "acoustic-banner"
      },
      "source": [
        "# 2- Data Analysis and Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "according-preservation",
      "metadata": {
        "id": "according-preservation"
      },
      "source": [
        "please note that the file of the training won't be included in the submitted folder due to submission size \n",
        "\n",
        "the dataset used :https://www.kaggle.com/kazanova/sentiment140?select=training.1600000.processed.noemoticon.csv "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mediterranean-ceramic",
      "metadata": {
        "id": "mediterranean-ceramic"
      },
      "outputs": [],
      "source": [
        "training_data = spark.read.csv(os.getcwd()+\"/training_data.csv\", inferSchema = True, header = False) #Read in the data\n",
        "#training_data.show(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "extra-batch",
      "metadata": {
        "id": "extra-batch"
      },
      "outputs": [],
      "source": [
        "columns = [\"target\", \"id\", \"date\", \"flag\", \"user\", \"tweet\"]  \n",
        "\n",
        "training_data = training_data.select(col(\"_c0\").alias(columns[0]), col(\"_c1\").alias(columns[1]), col(\"_c2\").alias(columns[2]),\n",
        "                      col(\"_c3\").alias(columns[3]), col(\"_c4\").alias(columns[4]), col(\"_c5\").alias(columns[5]))\n",
        "#training_data.show(10) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "altered-myanmar",
      "metadata": {
        "id": "altered-myanmar"
      },
      "source": [
        "No need for ids , data , flag and user data for  our target analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "built-standard",
      "metadata": {
        "id": "built-standard"
      },
      "outputs": [],
      "source": [
        "training_data = training_data.select('target' ,'tweet')\n",
        "#training_data.show(10) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "demographic-bhutan",
      "metadata": {
        "id": "demographic-bhutan"
      },
      "source": [
        "let's process our data ! "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "herbal-pottery",
      "metadata": {
        "id": "herbal-pottery",
        "outputId": "5202a1d3-f528-46fc-d3cd-9ddc360be5ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+-----+\n",
            "|target|tweet|\n",
            "+------+-----+\n",
            "|     0|    0|\n",
            "+------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_data.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in training_data.columns]).show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "earned-debate",
      "metadata": {
        "id": "earned-debate"
      },
      "source": [
        "we have no empyt data , so no need for imputation :)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "sapphire-alert",
      "metadata": {
        "id": "sapphire-alert"
      },
      "source": [
        "let's check out target values distribution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mobile-charter",
      "metadata": {
        "id": "mobile-charter",
        "outputId": "a8831e0c-6ed9-48ab-d04a-cba9e55f2cf8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------+\n",
            "|target| count|\n",
            "+------+------+\n",
            "|     0|800000|\n",
            "|     4|800000|\n",
            "+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_data.groupBy(\"target\").count().orderBy(\"count\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "external-router",
      "metadata": {
        "id": "external-router"
      },
      "source": [
        "No neutral values !! "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "broken-worry",
      "metadata": {
        "id": "broken-worry"
      },
      "source": [
        "Standarize our target values into 0s and 1s "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "transsexual-locking",
      "metadata": {
        "id": "transsexual-locking",
        "outputId": "55abe8cb-2681-4f12-e074-0e4ace5de024"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------+\n",
            "|target| count|\n",
            "+------+------+\n",
            "|     1|800000|\n",
            "|     0|800000|\n",
            "+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_data = training_data.withColumn(\"target\", when(training_data[\"target\"] == 4, 1).otherwise(training_data[\"target\"]))\n",
        "training_data.groupBy(\"target\").count().orderBy(\"count\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exposed-record",
      "metadata": {
        "id": "exposed-record"
      },
      "source": [
        "# The assumption here.. There's no neutral values \n",
        "\n",
        "# 1 => postive (Happy)  & 0 => negative (Sad)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "consecutive-edward",
      "metadata": {
        "id": "consecutive-edward"
      },
      "source": [
        "let's know more about the nature of our tweets data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "respected-shape",
      "metadata": {
        "id": "respected-shape",
        "outputId": "8a09a71e-b04e-4f7d-ed45-2112946c20fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------------------------------------------------------------------------------------------------------------------+\n",
            "|tweet                                                                                                                |\n",
            "+---------------------------------------------------------------------------------------------------------------------+\n",
            "|@switchfoot http://twitpic.com/2y1zl - Awww, that's a bummer.  You shoulda got David Carr of Third Day to do it. ;D  |\n",
            "|is upset that he can't update his Facebook by texting it... and might cry as a result  School today also. Blah!      |\n",
            "|@Kenichan I dived many times for the ball. Managed to save 50%  The rest go out of bounds                            |\n",
            "|my whole body feels itchy and like its on fire                                                                       |\n",
            "|@nationwideclass no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.       |\n",
            "|@Kwesidei not the whole crew                                                                                         |\n",
            "|Need a hug                                                                                                           |\n",
            "|@LOLTrish hey  long time no see! Yes.. Rains a bit ,only a bit  LOL , I'm fine thanks , how's you ?                  |\n",
            "|@Tatiana_K nope they didn't have it                                                                                  |\n",
            "|@twittera que me muera ?                                                                                             |\n",
            "|spring break in plain city... it's snowing                                                                           |\n",
            "|I just re-pierced my ears                                                                                            |\n",
            "|@caregiving I couldn't bear to watch it.  And I thought the UA loss was embarrassing . . . . .                       |\n",
            "|@octolinz16 It it counts, idk why I did either. you never talk to me anymore                                         |\n",
            "|@smarrison i would've been the first, but i didn't have a gun.    not really though, zac snyder's just a doucheclown.|\n",
            "|@iamjazzyfizzle I wish I got to watch it with you!! I miss you and @iamlilnicki  how was the premiere?!              |\n",
            "|Hollis' death scene will hurt me severely to watch on film  wry is directors cut not out now?                        |\n",
            "|about to file taxes                                                                                                  |\n",
            "|@LettyA ahh ive always wanted to see rent  love the soundtrack!!                                                     |\n",
            "|@FakerPattyPattz Oh dear. Were you drinking out of the forgotten table drinks?                                       |\n",
            "+---------------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_data.select(\"tweet\").show(20,truncate= False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "final-joshua",
      "metadata": {
        "id": "final-joshua"
      },
      "source": [
        "# Tweets need to be more cleans..\n",
        "\n",
        "mentions , links , hashtags and HTML elements .. have to be removed from our data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "informal-industry",
      "metadata": {
        "id": "informal-industry",
        "outputId": "174c5040-e02a-447a-fdb6-cec3de00b069"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1600000"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "annoying-taiwan",
      "metadata": {
        "id": "annoying-taiwan"
      },
      "outputs": [],
      "source": [
        "\n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', r'http\\S+', '')) \n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', '@\\w+', '')) \n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', '#', ''))\n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', 'RT', ''))\n",
        "\n",
        "\n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', '&amp;', ''))\n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', '&quot;', ''))\n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', '&gt;', ''))\n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', '&lt;', ''))\n",
        "\n",
        "\n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', '-', ''))\n",
        "\n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', '   ', ' '))\n",
        "training_data = training_data.withColumn('tweet', F.regexp_replace('tweet', '  ', ' '))\n",
        "\n",
        "\n",
        "training_data = training_data.filter((training_data.tweet!= ' ') &(training_data.tweet!= '')& (training_data.tweet!= '   '))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "accessible-burst",
      "metadata": {
        "id": "accessible-burst",
        "outputId": "209b813b-ea64-4919-8359-903f31e40135"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1597182"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "training_data.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "written-montgomery",
      "metadata": {
        "id": "written-montgomery",
        "outputId": "9d90190b-4156-4b9f-dc3a-53e76120e5cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------+------+\n",
            "|target| count|\n",
            "+------+------+\n",
            "|     0|798491|\n",
            "|     1|798691|\n",
            "+------+------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_data.groupBy(\"target\").count().orderBy(\"count\").show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "favorite-thickness",
      "metadata": {
        "id": "favorite-thickness"
      },
      "source": [
        "Now we can split randomly our training data into train and test set "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "finnish-bundle",
      "metadata": {
        "id": "finnish-bundle"
      },
      "outputs": [],
      "source": [
        "Train_Test_sets = training_data.randomSplit([0.75, 0.25])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "institutional-durham",
      "metadata": {
        "id": "institutional-durham"
      },
      "outputs": [],
      "source": [
        "train_set = Train_Test_sets[0] \n",
        "test_set = Train_Test_sets[1] \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "duplicate-sheet",
      "metadata": {
        "id": "duplicate-sheet",
        "outputId": "d10c16aa-da40-4d91-bae8-654f753630d5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "|tweet                                                                                                         |\n",
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "| Awww, that's a bummer. You shoulda got David Carr of Third Day to do it. ;D                                  |\n",
            "|is upset that he can't update his Facebook by texting it... and might cry as a result School today also. Blah!|\n",
            "| I dived many times for the ball. Managed to save 50% The rest go out of bounds                               |\n",
            "|my whole body feels itchy and like its on fire                                                                |\n",
            "| no, it's not behaving at all. i'm mad. why am i here? because I can't see you all over there.                |\n",
            "| not the whole crew                                                                                           |\n",
            "|Need a hug                                                                                                    |\n",
            "| hey long time no see! Yes.. Rains a bit ,only a bit LOL , I'm fine thanks , how's you ?                      |\n",
            "| nope they didn't have it                                                                                     |\n",
            "| que me muera ?                                                                                               |\n",
            "|spring break in plain city... it's snowing                                                                    |\n",
            "|I just repierced my ears                                                                                      |\n",
            "| I couldn't bear to watch it. And I thought the UA loss was embarrassing . . . . .                            |\n",
            "| It it counts, idk why I did either. you never talk to me anymore                                             |\n",
            "| i would've been the first, but i didn't have a gun. not really though, zac snyder's just a doucheclown.      |\n",
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "only showing top 15 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "training_data.select(\"tweet\").show(15,truncate= False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cheap-attempt",
      "metadata": {
        "id": "cheap-attempt"
      },
      "source": [
        "The data is more clean now"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "intensive-salvation",
      "metadata": {
        "id": "intensive-salvation"
      },
      "source": [
        "# 3- Pipeline and Training SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "contrary-ivory",
      "metadata": {
        "id": "contrary-ivory"
      },
      "source": [
        "The pipeline based on sparkNLP annotators and it consits of 10 stages "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "contemporary-montana",
      "metadata": {
        "id": "contemporary-montana"
      },
      "source": [
        "# 3-a Turn tweets into documents (Document Assembler)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "directed-winning",
      "metadata": {
        "id": "directed-winning"
      },
      "source": [
        "this is a basic step to start work with sparkNLP annotators"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "charged-samba",
      "metadata": {
        "id": "charged-samba"
      },
      "outputs": [],
      "source": [
        "document_assembler = DocumentAssembler() \\\n",
        "    .setInputCol(\"tweet\") \\\n",
        "    .setOutputCol(\"document\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "extra-asset",
      "metadata": {
        "id": "extra-asset"
      },
      "source": [
        "# 3-b Create sentences from documents (Sentences Detector )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "infinite-relation",
      "metadata": {
        "id": "infinite-relation"
      },
      "outputs": [],
      "source": [
        "dentence_detector = SentenceDetector() \\\n",
        "    .setInputCols([\"document\"]) \\\n",
        "    .setOutputCol(\"sentence\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "scientific-theology",
      "metadata": {
        "id": "scientific-theology"
      },
      "source": [
        "# 3-c Turn these sentences into tokens (Tokenizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "brown-development",
      "metadata": {
        "id": "brown-development"
      },
      "source": [
        "in this stage, sentences are split into words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "operating-million",
      "metadata": {
        "id": "operating-million"
      },
      "outputs": [],
      "source": [
        "tokenizer = Tokenizer() \\\n",
        "  .setInputCols([\"sentence\"]) \\\n",
        "  .setOutputCol(\"token\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "beneficial-desperate",
      "metadata": {
        "id": "beneficial-desperate"
      },
      "source": [
        "# 3-d Remove stop words from tokens (Stop Words Cleaner)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "crazy-township",
      "metadata": {
        "id": "crazy-township"
      },
      "source": [
        "stop words like I, you, me and so on are removed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "reserved-virtue",
      "metadata": {
        "id": "reserved-virtue"
      },
      "outputs": [],
      "source": [
        "stopwords_cleaner = StopWordsCleaner()\\\n",
        "      .setInputCols(\"token\")\\\n",
        "      .setOutputCol(\"cleanTokens\")\\\n",
        "      .setCaseSensitive(False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "exceptional-hometown",
      "metadata": {
        "id": "exceptional-hometown"
      },
      "source": [
        "# 3- e,f Remove punctautions and turn the documented_tokens into array of tokens (Normalizer , Finisher)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "considerable-florence",
      "metadata": {
        "id": "considerable-florence"
      },
      "outputs": [],
      "source": [
        "normalizer = Normalizer() \\\n",
        "    .setInputCols([\"cleanTokens\"]) \\\n",
        "    .setOutputCol(\"normalized\")\\\n",
        "    .setLowercase(True)\n",
        "\n",
        "finisher = Finisher() \\\n",
        "    .setInputCols([\"normalized\"]) \\\n",
        "    .setOutputCols([\"token_features\"]) \\\n",
        "    .setOutputAsArray(True) \\\n",
        "    .setCleanAnnotations(False)# To generate Term Frequency\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "published-officer",
      "metadata": {
        "id": "published-officer"
      },
      "source": [
        "# 3-g Hashing the tokens (hashingTF or Vectorization)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "drawn-following",
      "metadata": {
        "id": "drawn-following"
      },
      "outputs": [],
      "source": [
        "hashingTF = HashingTF(inputCol=\"token_features\", outputCol=\"rawFeatures\")# To generate Inverse Document Frequency\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "informal-reunion",
      "metadata": {
        "id": "informal-reunion"
      },
      "outputs": [],
      "source": [
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\", minDocFreq=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "rental-perception",
      "metadata": {
        "id": "rental-perception"
      },
      "source": [
        "# 3-h Classification based on the hashed tokens using Suppor Vector Machine"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "diverse-metabolism",
      "metadata": {
        "id": "diverse-metabolism"
      },
      "source": [
        "Our problem is a binary classification one. We could use many classifier based on ML like SVM , XGBoost ,Decision tree, Random Forest\n",
        "\n",
        "and we can use DNN to get a higher accuracy. But due to ram space and time constraints \n",
        "\n",
        "I had to choose a ML-approach which is the SVM. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "imposed-county",
      "metadata": {
        "id": "imposed-county"
      },
      "outputs": [],
      "source": [
        "SVC = LinearSVC(labelCol = \"target\", featuresCol=\"features\",maxIter=13, regParam=0.2)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aging-uncle",
      "metadata": {
        "id": "aging-uncle"
      },
      "source": [
        "let's create the promising Pipeline "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "surrounded-touch",
      "metadata": {
        "id": "surrounded-touch"
      },
      "outputs": [],
      "source": [
        "nlp_pipeline = Pipeline(\n",
        "    stages=[document_assembler, \n",
        "            dentence_detector,\n",
        "            tokenizer,\n",
        "            stopwords_cleaner,\n",
        "            normalizer,\n",
        "            finisher,\n",
        "            hashingTF,\n",
        "            idf,\n",
        "            SVC])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "clear-waters",
      "metadata": {
        "id": "clear-waters",
        "outputId": "ec6f1224-b1dd-45d2-97e1-7caa9675a036"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training finally Done !!!!\n"
          ]
        }
      ],
      "source": [
        "pipeline_model = nlp_pipeline.fit(train_set)\n",
        "print(\"Training finally Done !!!!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "adjacent-trademark",
      "metadata": {
        "id": "adjacent-trademark"
      },
      "source": [
        "# 4- Evaluation on training and testing tweets sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "distinct-spirit",
      "metadata": {
        "id": "distinct-spirit"
      },
      "outputs": [],
      "source": [
        "def evaluate(input_set):\n",
        "    results=pipeline_model.transform(input_set)\n",
        "    evaluator = MulticlassClassificationEvaluator(labelCol=\"target\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "    accuracy = evaluator.evaluate(results)\n",
        "    print(\"Accuracy = %g\" % (accuracy))\n",
        "    print(\"Error = %g \" % (1.0 - accuracy))\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "brown-belief",
      "metadata": {
        "id": "brown-belief"
      },
      "source": [
        "# THE ACCURACY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "painful-literature",
      "metadata": {
        "id": "painful-literature",
        "outputId": "f05df911-b6dc-4d65-f8c5-ac23f604a53c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.792393\n",
            "Error = 0.207607 \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7923931156785957"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(train_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "based-cemetery",
      "metadata": {
        "id": "based-cemetery",
        "outputId": "7005d471-f4ee-415d-adac-dde174dd79b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.771817\n",
            "Error = 0.228183 \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.7718168384056234"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(test_set)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "insured-programming",
      "metadata": {
        "id": "insured-programming"
      },
      "outputs": [],
      "source": [
        "pipeline_model.save(\"/pipeline\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acting-physics",
      "metadata": {
        "id": "acting-physics"
      },
      "source": [
        "After many trails and experiments , I could get a goot results which are around 79.2%  and 77.2% on train and test sets, respectively !!\n",
        "\n",
        "I considerd it an achievement, as the satate of art pipeline could achieve only about 80 % .\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "agreed-employment",
      "metadata": {
        "id": "agreed-employment"
      },
      "source": [
        "# **** TO RUN MY PIPELINE ****"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "laden-orbit",
      "metadata": {
        "id": "laden-orbit"
      },
      "source": [
        "Kindly import the neccesay packages and start a session as explained above ans resume execution from here instead of training the model yourself"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eleven-closing",
      "metadata": {
        "id": "eleven-closing"
      },
      "source": [
        "please make sure that you point to the correct pipeline path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "printable-elite",
      "metadata": {
        "id": "printable-elite"
      },
      "outputs": [],
      "source": [
        "pipeline_model=PipelineModel.load(\"/pipeline\")\n",
        "\n",
        "def predict(line): # function to make a predection on a tweet or line and outout happy or sad\n",
        "    sample_df = spark.createDataFrame([[str(line)]]).toDF('tweet')\n",
        "    #-- preprocessing---\n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', r'http\\S+', '')) \n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', '@\\w+', '')) \n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', '#', ''))\n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', 'RT', ''))\n",
        "\n",
        "\n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', '&amp;', ''))\n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', '&quot;', ''))\n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', '&gt;', ''))\n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', '&lt;', ''))\n",
        "\n",
        "\n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', '-', ''))\n",
        "\n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', '   ', ' '))\n",
        "    sample_df = sample_df.withColumn('tweet', F.regexp_replace('tweet', '  ', ' '))\n",
        "\n",
        "    \n",
        "    #---\n",
        "    \n",
        "    result = pipeline_model.transform(sample_df)\n",
        "    sentiment = result.select('prediction').first()[0]\n",
        "    if(sentiment == 1):\n",
        "        sentiment = \"Happy\"\n",
        "        print (str(line)+ \" =====> \"+\"HAPPY\")\n",
        "    else:\n",
        "        sentiment = \"Sad\"\n",
        "        print(str(line)+ \" =====> \"+\"HAPPY\")\n",
        "\n",
        "    return line , sentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "brown-german",
      "metadata": {
        "id": "brown-german"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "flying-thanksgiving",
      "metadata": {
        "id": "flying-thanksgiving"
      },
      "source": [
        "#on a Real-Life Conversations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "alternative-report",
      "metadata": {
        "id": "alternative-report",
        "outputId": "5625c3d2-cd32-45c1-f386-6f7508e0ecdd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iam really happy right now. =====> HAPPY\n",
            "Easy Task!  =====> HAPPY\n",
            "I will be sad if not accepted =====> HAPPY\n",
            "I am alone =====> HAPPY\n",
            "My day was full of good events but at the end , a car hit me and broke my leg =====> HAPPY\n",
            "Death. =====> HAPPY\n",
            "I failed in my last exam =====> HAPPY\n",
            "my dad bought me a new car =====> HAPPY\n",
            "the new car my dad bought me was crashed :( =====> HAPPY\n",
            "I am nervous =====> HAPPY\n",
            "I helped many people today =====> HAPPY\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "('I helped many people today', 'Happy')"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "predict(\"Iam really happy right now.\") # =>1\n",
        "predict(\"Easy Task! \")# =>1\n",
        "predict(\"I will be sad if not accepted\") #=>0\n",
        "predict(\"I am alone\")# =>0\n",
        "predict(\"My day was full of good events but at the end , a car hit me and broke my leg\")# =>0\n",
        "predict(\"Death.\") #=>0\n",
        "predict(\"I failed in my last exam\") #=>0\n",
        "predict(\"my dad bought me a new car\") #=>1\n",
        "predict(\"the new car my dad bought me was crashed :(\") #=>0\n",
        "predict(\"I am nervous\") #=>0\n",
        "predict(\"I helped many people today\") #=>1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "threatened-courtesy",
      "metadata": {
        "id": "threatened-courtesy"
      },
      "source": [
        "--\n",
        "\n",
        "All of them predicted correctly !! "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "micro-transsexual",
      "metadata": {
        "id": "micro-transsexual"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aggressive-official",
      "metadata": {
        "id": "aggressive-official"
      },
      "source": [
        "dataset: https://www.kaggle.com/c/sentiment-analysis-on-movie-reviews/data\n",
        "\n",
        "\n",
        "I use the train_set only"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "endangered-panic",
      "metadata": {
        "id": "endangered-panic"
      },
      "outputs": [],
      "source": [
        "rotten_set = spark.read.csv(os.getcwd()+\"/reviews.tsv\", sep=r'\\t', header=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "rough-graphics",
      "metadata": {
        "id": "rough-graphics",
        "outputId": "3f10d1f5-ed98-4ee0-c982-36fcb39a25b1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+--------------------+------+\n",
            "|               tweet|target|\n",
            "+--------------------+------+\n",
            "|A series of escap...|   0.0|\n",
            "|  good for the goose|   1.0|\n",
            "|                good|   1.0|\n",
            "|the gander , some...|   0.0|\n",
            "|              amuses|   1.0|\n",
            "|but none of which...|   0.0|\n",
            "|none of which amo...|   0.0|\n",
            "|This quiet , intr...|   1.0|\n",
            "|This quiet , intr...|   1.0|\n",
            "|quiet , introspec...|   1.0|\n",
            "+--------------------+------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rotten_set.show(10,truncate= True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "focal-graphic",
      "metadata": {
        "id": "focal-graphic"
      },
      "outputs": [],
      "source": [
        "rotten_set = rotten_set.select('Phrase' ,'Sentiment')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "organic-niger",
      "metadata": {
        "id": "organic-niger",
        "outputId": "5168b5a2-0957-437b-8d31-62081870cb7c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+-----+\n",
            "|Sentiment|count|\n",
            "+---------+-----+\n",
            "|        0| 7072|\n",
            "|        4| 9206|\n",
            "|        1|27273|\n",
            "|        3|32927|\n",
            "|        2|79582|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rotten_set.groupBy(\"Sentiment\").count().orderBy(\"count\").show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mechanical-authentication",
      "metadata": {
        "id": "mechanical-authentication",
        "outputId": "e95c593f-b149-4714-a9c3-623341b1ef37"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+---------+-----+\n",
            "|Sentiment|count|\n",
            "+---------+-----+\n",
            "|        0|34345|\n",
            "|        1|42133|\n",
            "+---------+-----+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rotten_set = rotten_set.withColumn(\"Sentiment\", when(rotten_set[\"Sentiment\"] ==1, 0).otherwise(rotten_set[\"Sentiment\"]))\n",
        "rotten_set = rotten_set.withColumn(\"Sentiment\", when(rotten_set[\"Sentiment\"] ==3, 4).otherwise(rotten_set[\"Sentiment\"]))\n",
        "rotten_set = rotten_set.withColumn(\"Sentiment\", when(rotten_set[\"Sentiment\"] ==4, 1).otherwise(rotten_set[\"Sentiment\"]))\n",
        "rotten_set = rotten_set.filter((rotten_set.Sentiment!= 2))\n",
        "rotten_set.groupBy(\"Sentiment\").count().orderBy(\"count\").show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "skilled-shopper",
      "metadata": {
        "tags": [],
        "id": "skilled-shopper"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.types import DoubleType\n",
        "rotten_set = rotten_set.select(col(\"Phrase\").alias(\"tweet\"), col(\"Sentiment\").alias(\"target\"))\n",
        "rotten_set = rotten_set.withColumn(\"target\", rotten_set.target.cast(DoubleType()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "mexican-violation",
      "metadata": {
        "id": "mexican-violation",
        "outputId": "fbf1d94a-5b6a-42cb-c098-eb58ef86e86c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy = 0.674874\n",
            "Error = 0.325126 \n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.6748738199220691"
            ]
          },
          "execution_count": 226,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "evaluate(rotten_set)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "blank-ferry",
      "metadata": {
        "id": "blank-ferry"
      },
      "source": [
        "It's not a bad accuracy. However, the drop in accuracy happens to the difference between the nature of pipeline training data and this data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "responsible-bicycle",
      "metadata": {
        "id": "responsible-bicycle"
      },
      "source": [
        "# The Real-Time Streaming Sentiment Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "acknowledged-grace",
      "metadata": {
        "id": "acknowledged-grace"
      },
      "source": [
        "Now, real tweets is being streamed to be prediceted on my pipeline \n",
        "\n",
        "the tweets are tracked on different keywords like Egypt, Usa, happy, sad , feeling and so on \n",
        "\n",
        "every tweet is predicted individually in this form, tweet ====> sentiment prediction"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "corresponding-anaheim",
      "metadata": {
        "id": "corresponding-anaheim"
      },
      "source": [
        "# Keywords = {happy,sad,feeling,sentiment}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "advanced-relationship",
      "metadata": {
        "id": "advanced-relationship",
        "outputId": "6530fe91-4fb6-4fe2-9820-eb3475506875"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "@FreeTrap2x Mfs donâ€™t even know the definition of misogyny ðŸ˜‚ðŸ˜‚sad =====> SAD\n",
            "(to the tune of The Devil Went Down To Georgia)\n",
            "\n",
            "ðŸŽ¶ Russell Greer went down to Vegas , he was lookin' for a whore toâ€¦ https://t.co/r8Vfn5OH3J =====> SAD\n",
            "RT @BayouBun: Bow Wow came with the steel chair when he said puffy ainâ€™t got a artist wit a milli and happy =====> HAPPY\n",
            "RT @MeganMorantWWE: I canâ€™t wait for @YaOnlyLivvOnce vs @CarmellaWWE at #ExtremeRules ðŸ™Œ =====> HAPPY\n",
            "Itâ€™s real sadboi hours! Hit me with your best sad songs, doesnâ€™t matter what genre. Classical, orchestral, rap, hip hop, doesnâ€™t matter. =====> SAD\n",
            "RT @BTSupdate_7: Look at Jimin happily dancing and waving ðŸ˜­ðŸ˜­ðŸ˜­ðŸ¤—ðŸ¤—\n",
            "\n",
            "They are really happy ~\n",
            "\n",
            " https://t.co/qe0Em4Z811 =====> HAPPY\n",
            "RT @DomainDoris: Iâ€™m not plotting mischief, Iâ€™m an innocent floof! Happy #Caturday pals! ðŸ¾ðŸ¥°ðŸ¾ #CatsOfTwitter #Cat #cats #pets #animals ðŸ’™ #Caâ€¦ =====> HAPPY\n",
            "RT @AlwaysRamCharan: Introducing #Siddha's Love #Neelambari ! \n",
            "Wishing you all a very Happy Ugadi.\n",
            "#Acharya\n",
            "@KChiruTweets @sivakoratala @heâ€¦ =====> HAPPY\n",
            "RT @TrendsAjith: Happy to reveal the first year anniversary celebration tag for @KeralaAjithFC team ! \n",
            "\n",
            "TAG:  #1YrOfPrideKeralaAjithFC\n",
            "\n",
            "#Ajâ€¦ =====> HAPPY\n",
            "Heâ€™s seen the sad tears only once before : an evening when the sun set low and the white hospital room walls were cast in orange. =====> SAD\n",
            "Mi mamita me contesto, im happy again =====> HAPPY\n",
            "Rossano Brazzi  #BOTD \n",
            "SUMMERTIME â€“ David Lean, 1955 \n",
            "#cinematography: Jack Hildyard \n",
            "#costumes: Rosi Gori\n",
            "w/ Kathaâ€¦ https://t.co/UJmSFPvcS1 =====> HAPPY\n",
            "Gm y'all how we feeling? =====> SAD\n",
            "RT @Ienscap: Happy Birthday James Gandolfini\n",
            "\n",
            "Rest in peace legend. https://t.co/y7UtaEPCaG =====> HAPPY\n",
            "RT @lazarusfaIIing: happy birthday to the only character to ever exist!!! #13YearsOfCastiel https://t.co/k39QaDICer =====> HAPPY\n",
            "RT @ColorfulMen72: ðŸŒ¸ðŸ†ðŸ§”ðŸ»ðŸ•³ðŸ‘¦ðŸ½ happy Saturday\n",
            "\n",
            "@dilf2050 @brotheragensbr  @themusculartime @JuanLovesCock @hot_connection2 @FrenchGaymer @BOKEPâ€¦ =====> HAPPY\n",
            "RT @lovedsickgirls: lisa looked so sad when she got asked about variety shows. i hope she knows we appreciate all her efforts to put out coâ€¦ =====> SAD\n",
            "RT @sakshijoshii: .@INCIndia doesnâ€™t reward those who win elections for them \n",
            "\n",
            "Amidst a huge Modi wave, @capt_amarinder took back power froâ€¦ =====> SAD\n",
            "RT @linoscent: dori being almost as big as soonie and doongie now i'm sad https://t.co/E8TpEMXIxs =====> SAD\n",
            "RT @KBMcGee86: I'm a #Fansbury for the reason she's a wonderful human being an always appreciate that hard work pays off an even at her ageâ€¦ =====> HAPPY\n",
            "RT @mingeniusloverr: Iâ€™m so happy to see my beautiful man. We love you and miss you, Yoongi! Have a safe flight #SUGA  @BTS_twt ðŸ’™ \n",
            "\n",
            "PROUD Oâ€¦ =====> HAPPY\n",
            "@shujigives @shiepromotes happy 18th =====> HAPPY\n",
            "RT @taetaction: look how hobi is watching them i'm so sad https://t.co/bkOvououUd =====> SAD\n",
            "RT @imjadeja: Many happy returns of the day to our honourable PM @narendramodi ji.\n",
            "Wishing him the very best on his special day ðŸ™ =====> HAPPY\n",
            "@VIP_IDiKONIC The satisfaction on Chanwoo's face looking at June happy ðŸ¥º =====> HAPPY\n",
            "RT @ddowouon: MY GORGEOUS LITTLE SISTER ðŸ˜ =====> HAPPY\n",
            "RT @AfcThrissur: Happy to Launch the 1 Year Anniversary Tag for @KeralaAjithFC. Kerala Ajith  Fans State Committee was formed 22 Years Ago.â€¦ =====> HAPPY\n",
            "RT @jakesimthings: Happy 1st Anniversary Jake from Enhypen. â¤ https://t.co/Uskgcj5HEr =====> HAPPY\n",
            "@Peachfront @TradingTaylor @DocMCohen This happens for everything actually. If someone gets shot near you and you fâ€¦ https://t.co/FFHxCVB3Uv =====> SAD\n",
            "RT @bts_ot7_ly: @Namjo0onie Happy birthday â¤â¤â¤ =====> HAPPY\n",
            "SAD ENDING DONG =====> SAD\n",
            "RT @Trend_pages: Happy to Launch the 1 Year Anniversary Tag for @KeralaAjithFC. Kerala Ajith  Fans State Committee was formed 22 Years Ago.â€¦ =====> HAPPY\n",
            "RT @OnlineSuriyaFT: Happy Birthday #Vinay sir on behalf of Suriya anna fans ðŸ’“ðŸ’\n",
            "\n",
            "Waiting For #EtharkkumThunindhavan ðŸ˜‰âœŒðŸ»&amp; Best wishes for youâ€¦ =====> HAPPY\n",
            "RT @hrjhops: why be sad when you have renjun\n",
            "https://t.co/gPjGpUWlBs =====> SAD\n",
            "RT @Olie_edwin: For the love of sports \n",
            "Happy birthday  our sports queen ðŸ‘‘ @CarolRadull \n",
            "Your impact on the world of sports is commendable.â€¦ =====> HAPPY\n",
            "Today Gakuran-kun is happy! He must be having a good day! :D https://t.co/FpEAUiZAkq =====> HAPPY\n",
            "RT @ACTORAJITH_FANS: Happy to reveal the first year anniversary celebration tag for @KeralaAjithFC team ! \n",
            "\n",
            "TAG:  #1YrOfPrideKeralaAjithFCâ€¦ =====> HAPPY\n",
            "Still sick, im so sad, no stream again today.. Really want to stream but cant bc im sick. ðŸ¤’ðŸ™ =====> SAD\n",
            "Sad hours  https://t.co/KbZG44CnsT =====> SAD\n",
            "RT @MoneydefiSwap: Together the future with MoneydefiSwapðŸš€ðŸ”¥\n",
            "We are happy to announce that Trade $MSD is now available on Hotbit exchanges ðŸŒ¬â€¦ =====> HAPPY\n",
            "@virginia_spotts Aahh happy birthday to you AND your skin! =====> HAPPY\n",
            "RT @XXL: Happy birthday, @xzibit! ðŸŽ‰\n",
            "\n",
            "Whatâ€™s your favorite song of his? https://t.co/qmV3LLIV8C =====> HAPPY\n",
            "RT @That_Lex: Iâ€™m doing it tired. Iâ€™m doing it sad. Iâ€™m doing it scared. Idgaf! Iâ€™m doing it. =====> SAD\n",
            "RT @saebits: happy 1 year to mr. heart thank u for giving us one of my fav couples ever &lt;3\n",
            "[ #LeeSeJin #CheonSeungHo #MrHeart #ë¯¸ìŠ¤í„°í•˜íŠ¸ ] httpâ€¦ =====> HAPPY\n",
            "RT @official__INI: â–²â–¼â”â”â”â”â”â”â”â”â”\n",
            "   #HAPPYTAKUMIDAY\n",
            " â”â”â”â”â”â”â”â”â” â–²â–¼\n",
            "\n",
            "    HAPPY BIRTHDAY \n",
            "            TAKUMI\n",
            "           20210614\n",
            "\n",
            "#INI #ã‚¢ã‚¤ã‚¨ãƒŒã‚¢ã‚¤â€¦ =====> HAPPY\n",
            "@buyabes_fatma Happy birthday Buyabis ðŸ˜˜ðŸŽˆâ¤ï¸ =====> HAPPY\n",
            "RT @dailyjimitonin: Look at our Jimin waving everyone!!\n",
            "Heâ€™s so kind! Happy Journey Jiminie, have a safe flight to New York !!! We love youâ€¦ =====> HAPPY\n",
            "@elonmusk @SpaceX #PEC smart chain wishes you a Happy Mid Autumn Festival @V2Chain https://t.co/7zWL13kCpV =====> HAPPY\n",
            "RT @rameshlaus: Happy to Launch the 1 Year Anniversary Tag for @KeralaAjithFC. Kerala Ajith  Fans State Committee was formed 22 Years Ago.â€¦ =====> HAPPY\n",
            "@Trumpeteer14 I feel that way too.  \n",
            "I'm disturbed by the current sad situation in the USA &amp; the world but I don'tâ€¦ https://t.co/RDm0IWPkC0 =====> SAD\n",
            "@QueenLeora Happy birthdaaay!! ðŸŽˆðŸŽˆðŸŽˆðŸŽ‰ =====> HAPPY\n",
            "RT @woniekook: heeseung: â€œjungwon always comes in my room and says good night with his killer smileâ€\n",
            "\n",
            "no because heâ€™s been doing this sinceâ€¦ =====> HAPPY\n",
            ".@hastyqt happy birthday bossðŸ˜Œ =====> HAPPY\n",
            "RT @iingwen: Wishing a happy Mid-Autumn Festival to all in #Taiwan &amp; across the world. Letâ€™s keep working together to fight this pandemic,â€¦ =====> HAPPY\n",
            "@ArnoldLabour Hi Arnold, we are happy to help. Please follow our support page: [https://t.co/RyfgUDsGU8] so our Ubeâ€¦ https://t.co/Hv08e28hk1 =====> HAPPY\n",
            "RT @JorgeJimenezArt: Lately every day is Batman day for me, but still,:D  HAPPY BATMAN DAY, FRIENDS! #HappyBatmanDay #batman @tomeu_morey câ€¦ =====> HAPPY\n",
            "RT @httpsukkiee: HAPPY FIRST YEAR TO THIS MASTERPIECEðŸŽ‰ @treasuremembers https://t.co/m9qqPRl3YB =====> HAPPY\n",
            "RT @lali_031827: im sad for lisa, it breaks my heart she deserves betterðŸ’” =====> SAD\n",
            "RT @exolyoutubeteam: EXO ì—‘ì†Œ 'Don't fight the feeling' MV\n",
            "\n",
            "85,987,906 views\n",
            "\n",
            "86M coming later today, right? Have you streamed at least onceâ€¦ =====> HAPPY\n",
            "RT @GinoTorretta: Happy College Football Saturday!  Enjoy the games. https://t.co/jyK2CA3n5P =====> HAPPY\n",
            "RT @AlwaysRamCharan: I wish everyone a happy and prosperous year ahead...ðŸ˜Š\n",
            "\n",
            "à°‰à°—à°¾à°¦à°¿ à°¶à±à°­à°¾à°•à°¾à°‚à°•à±à°·à°²à±.\n",
            "#à²¯à³à²—à²¾à²¦à²¿ #GudiPadwa #à¤¨à¤µà¤¸à¤‚à¤µà¤¤à¥à¤¸à¤° #à®¤à®®à®¿à®´à¯à®ªà¯à®ªà¯à®¤à¯â€¦ =====> HAPPY\n",
            "RT @aussieblair: Happy Friday everyone ðŸ¤˜ðŸ½ https://t.co/XXBvlCu6A9 =====> HAPPY\n",
            "RT @RanbirKUniverse: Happy Independence Day â¤\n",
            "\n",
            "Credit to uploader \n",
            "\n",
            "#RanbirKapoor https://t.co/6hYnSt01E5 =====> HAPPY\n",
            "Strange feeling prints. There seemed no reason to trust a man's faith in God meant\n",
            "\n",
            "âœŒï¸ðŸŽ—ï¸\n",
            "... &lt;&amp;lt;ÙƒÙ•ÙˆÙÙ“Ø¯Ù“ &gt;&gt;... \n",
            "NMâ€¦ https://t.co/ikhXqa7g9p =====> HAPPY\n",
            "@lowlvldemon We are very sorry that this has happened with your order and would like to investigate this further foâ€¦ https://t.co/WV7dw0o3vZ =====> SAD\n",
            "RT @iingwen: Wishing a happy Mid-Autumn Festival to all in #Taiwan &amp; across the world. Letâ€™s keep working together to fight this pandemic,â€¦ =====> HAPPY\n",
            "Happy to say that 2 of these films were used in my previous class hehe =====> HAPPY\n",
            "RT @TFC_mass: Happy to Launch the 1 Year Anniversary Tag for @KeralaAjithFC. All The Best Dear Team For All Your Future Works ðŸ˜Ž \n",
            "\n",
            "Tag ðŸ‘‰ #1Yâ€¦ =====> HAPPY\n",
            "I hope and you have had a safe flight\n",
            "I love you very much, take care of yourselves a lot and be happy @BTS_twt ðŸ’œ =====> HAPPY\n",
            "RT @FOXYGIVES: $12 | â‚±600 | 170.000 IDR\n",
            "\n",
            "- follow me ðŸ””\n",
            "- retweet + 60k\n",
            "\n",
            "Happy 60k everyone!ðŸ¥³ðŸ’— =====> HAPPY\n",
            "RT @DivaYnwa: Morning Lovelies ðŸ¥° \n",
            "\n",
            "Happy Matchday ðŸ”´ https://t.co/aoRFi77KTY =====> HAPPY\n",
            "@Cable_Darker To being myself again and we ended on a happy note. We finished off our food and then we went our sepâ€¦ https://t.co/M438Cad94i =====> SAD\n",
            "RT @BTSupdate_7: Look at Jimin happily dancing and waving ðŸ˜­ðŸ˜­ðŸ˜­ðŸ¤—ðŸ¤—\n",
            "\n",
            "They are really happy ~\n",
            "\n",
            " https://t.co/qe0Em4Z811 =====> HAPPY\n",
            "RT @mahonsunto: feeling wavey ðŸŒŠâœ¨ https://t.co/5GcSmPmUOr =====> SAD\n",
            "@neptufly halo ! good night ðŸ§šðŸ»â€â™€ï¸ how are you today? ðŸŒ· good ðŸ‘ðŸ» or bad ðŸ‘ŽðŸ» be happy yap ðŸ’“ i hope you have a nice sleeâ€¦ https://t.co/VSPxiREScS =====> HAPPY\n",
            "RT @btsarmy2018x: Look at Jimin dancing and waving, he looks so happy ðŸ˜­ https://t.co/4lXLA02zK2 =====> HAPPY\n",
            "RT @sleafordmods: Anti vaxers. Will you be happy when everyone is dead ? Would you be happier with square wheels on your motor? =====> HAPPY\n",
            "One year ago. Happy gotcha day Georgiana! https://t.co/MN4D1PNBB4 =====> HAPPY\n",
            "Happy heavenly birthday Truman â¤ï¸ https://t.co/xhySmx3oyR =====> HAPPY\n",
            "RT @kthpn: btw yall,, do not force taehyung to post something,, he will post when he wants to and when he fells more comfortable and we'llâ€¦ =====> HAPPY\n",
            "RT @LisaMarieBoothe: This is so sad. There is no humanity anymore. So many monsters. =====> SAD\n",
            "@xxjisatsu @uzendayon Cry like a baby, sad to be you ðŸ¼ =====> SAD\n",
            "@agustdeehee happy birthday luv ðŸ¥³ðŸ¤ =====> HAPPY\n",
            "Happy 1st AnnivðŸ˜˜ðŸ’• =====> HAPPY\n",
            "RT @GeethaArts: Wishing the 'Supreme Superstar @nimmaupendra' garu a very happy birthday, also we are extremely happy to have him as a partâ€¦ =====> HAPPY\n",
            "RT @Chlozee2: .\n",
            "\n",
            "Hello thank you so much for the 25k followers, I'm so happy ðŸ˜ðŸ˜ðŸ˜\n",
            "\n",
            "https://t.co/OhP8CuEali https://t.co/OadOGQ9Xap =====> HAPPY\n",
            "RT @90sfootball: Happy Birthday Ronaldo! https://t.co/ikVvZQeLVt =====> HAPPY\n",
            "RT @Number10cat: Happy #Caturday\n",
            "https://t.co/m8CSwNx6Rv =====> HAPPY\n",
            "Hey Larv... look 4ward to it\n",
            "\n",
            "N all the f1r3 I will spit\n",
            "\n",
            "Will b non 4 prophit \n",
            "\n",
            "U WON'T TORTURE her majesty againâ€¦ https://t.co/vO47ibvLiV =====> HAPPY\n",
            "@juanxkvui happy satnight gan =====> HAPPY\n",
            "RT @iksongsplaylist: really happy they gave us a sight of ikjun in specs for the last time ðŸ¥º https://t.co/VKupbchtPX =====> HAPPY\n",
            "RT @GajrajCorps_IA: #AzadiKaAmritMahotsav\n",
            "#IDC2021\n",
            "\n",
            "HAPPY INDEPENDENCE DAY \n",
            "\n",
            "@PMOIndia\n",
            "@DefenceMinIndia\n",
            "@SpokespersonMoD\n",
            "@adgpi\n",
            "@easterncomâ€¦ =====> HAPPY\n",
            "RT @renkiger_: â€œIâ€™m a big fan of BTS. I think theyâ€™re also national heroes. I think itâ€™s incredible. What they do for Korean ppl makes [me]â€¦ =====> HAPPY\n",
            "RT @Hoss21_: Happy Birthday to the coolest cat on twitter! @catturd2 https://t.co/APm0NyBp9X =====> HAPPY\n",
            "RT @HappypusNFT: Here is a unique Happypus collection inspired by Charles Hoskinson's own (Happy Octopus) mascot. \n",
            "\n",
            "#ADA #Cardano #NFT #CNFâ€¦ =====> SAD\n",
            "RT @lali_031827: im sad for lisa, it breaks my heart she deserves betterðŸ’” =====> SAD\n",
            "RT @RebaToTheRescue: Happy Saturday, Friends! Reba hopes that you head on over to @kweliTV for some sensational stories that you're sure toâ€¦ =====> HAPPY\n",
            "RT @jaekhoon: 25 pesos gcash giveaway bc JAKEHOON ðŸ˜­ + im jus rlly happy today ðŸ˜­\n",
            "\n",
            "rt + like\n",
            "no need to follow \n",
            "ends at 11pm!! ðŸ’¥ðŸ˜­ðŸ‘ðŸ» https://tâ€¦ =====> HAPPY\n",
            "RT @itosoewandi: Andree Bienfait...\n",
            "@bgv_online @ampomata @paulbar59067209 @BrindusaB1  @mujahidgrw @AnnaCountessK @dianadep1 @DavLucia\n",
            "\n",
            "Peâ€¦ =====> SAD\n",
            "RT @_TWnostalgia: Happy SIVA SATURDAY fanmily! The butterflies butterflies have started in my tummy as it's literally just hit me that mondâ€¦ =====> SAD\n",
            "RT @laurenkwinn: The Big Lie is alive and well in Pennsylvania and @JohnFetterman will be joining @mehdirhasan this morning on @VelshiMSNBCâ€¦ =====> HAPPY\n",
            "RT @sungwonfolder: happy 1st anniversary to our seven amazing boys @ENHYPEN_members, thank you for bringing us along on your journey of groâ€¦ =====> HAPPY\n",
            "RT @tn_ajith: Here we go let's celebrate One year of team @KeralaAjithFc in Twitter. \n",
            "\n",
            "TAG ðŸ‘‰ #1YrOfPrideKeralaAjithFc\n",
            "\n",
            "Happy to share our pâ€¦ =====> HAPPY\n",
            "For those fortunate students and tutors on @Pianolotmusic - and my  piano courses at Le Vert - this photo will brinâ€¦ https://t.co/aXlJ7FgSV1 =====> HAPPY\n",
            "RT @TFC_mass: Happy to Launch the 1 Year Anniversary Tag for @KeralaAjithFC. All The Best Dear Team For All Your Future Works ðŸ˜Ž \n",
            "\n",
            "Tag ðŸ‘‰ #1Yâ€¦ =====> HAPPY\n",
            "This is hilariously scary and sad. This statement alone. It is 2021 and they are still lost under the hood =====> SAD\n",
            "RT @yoonietangerine: it's so sad to know how you are all so active when it comes to some chismis but rarely hyping up about votings. pleaseâ€¦ =====> SAD\n",
            "To the boy who never got to grow up, the man who never really was, and the worldâ€™s greatest detective and superheroâ€¦ https://t.co/S8PZ03q6Vu =====> SAD\n",
            "RT @brfootball: Happy 45th birthday to El Fenomeno ðŸ‡§ðŸ‡· \n",
            "\n",
            "He was ðð¢ðŸðŸðžð«ðžð§ð­ â™¨ï¸\n",
            "(via @EuropaLeague)\n",
            "https://t.co/fz2QxFCDC6 =====> HAPPY\n",
            "RT @blckbsct: Happy Birthday @catturd2 hope itâ€™s the best one yet!\n",
            "#CatturdsBirthday https://t.co/b3tFGvIG8E =====> HAPPY\n",
            "RT @EchoLake_NSFW: a girl always needs another pair of handsâ€¦ even if they are just for feeling up this body\n",
            "\n",
            "rtâ€™s appreciated, but not expâ€¦ =====> HAPPY\n",
            "@funder @Aqua174 What to do when sad and lonely? =====> SAD\n",
            "This is a big opportunity. Made by a very professional and experienced team. Without a doubt, This is one of the beâ€¦ https://t.co/pbRAYzZVDQ =====> HAPPY\n",
            "RT @eye_kar: May God shower his choicest blessings on Eid. Wishing you a Happy Eid! #EidUlFitr https://t.co/T7YuCbU9o6 =====> HAPPY\n",
            "RT @muftimenk: The good and bad, happy and sad - these things will happen in your life. Try not to be upset, learn to take things in your sâ€¦ =====> SAD\n",
            "RT @LexiReign_: Happy Friday everyone! Ready to relax and enjoy the weekend?ðŸ˜˜ https://t.co/xwRlCUXddR =====> HAPPY\n",
            "RT @Funimation: Happy birthday to the incredible captain of the Black Bulls, Yami Sukehiro! â™£ï¸Ž\n",
            "\n",
            "[via Black Clover] https://t.co/PzVV8dh0l1 =====> HAPPY\n",
            "RT @JacksonWGlobal_: [INFO] 210918\n",
            "\n",
            "#JacksonWang is on 2 different shows tonight, both airing at the same time, 20:20 Beijing Time ðŸ˜†ðŸ¥³\n",
            "\n",
            "1ï¸âƒ£â€¦ =====> HAPPY\n",
            "Happy birthday, Cas. Oh my god, I miss you so much. This is making me sad but i know, you are still alive, in my heâ€¦ https://t.co/oKL4jLaJbH =====> SAD\n",
            "RT @Jeanna350: Happy Freaking Friday!! ðŸ˜ðŸ˜„ Have a Fantastic Day! ðŸ’œ Be Kind ðŸ’œðŸ¤— https://t.co/p2DSdGi8sw =====> HAPPY\n",
            "RT @popovmusic: Iâ€™m proud and happy to share our new single ANGEL in collaboration with legend @pauloakenfold OUT NOW on @interplayrec Streâ€¦ =====> HAPPY\n",
            "@catturd2 Happy birthday, Kitty-KittyðŸ¥³ =====> HAPPY\n"
          ]
        }
      ],
      "source": [
        "import tweepy\n",
        "from tweepy import Stream\n",
        "from tweepy.streaming import StreamListener\n",
        "from tweepy import OAuthHandler\n",
        "import socket\n",
        "import json\n",
        "\n",
        "class TweetsListener(StreamListener):\n",
        "    \n",
        "    def on_data(self, data):\n",
        "        msg = json.loads(data)\n",
        "        try:\n",
        "            predict(msg['text'])\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "\n",
        "\n",
        "    def on_error(self, status):\n",
        "        print(status)\n",
        "        return True\n",
        "\n",
        "auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_secret)\n",
        "twitter_stream = Stream(auth, TweetsListener())\n",
        "twitter_stream.filter(track = [\"happy\",\"sad\",\"feeling\",\"sentiment\"], languages=[\"en\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "played-construction",
      "metadata": {
        "id": "played-construction"
      },
      "source": [
        "# Keywords = {Egypt,USA}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "civil-happiness",
      "metadata": {
        "id": "civil-happiness",
        "outputId": "09c63425-7b05-444f-a6e0-65ba706ea99c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "RT @catturd2: ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚\n",
            "\n",
            "#CatturdsBirthday is the #2 trend in the USA =====> HAPPY\n",
            "RT @chapps: *Who* is this #handsome rogue? Wonderful details in the hair, and an appropriately Hadrianic beard for c. 125 AD. Sadly, a funeâ€¦ =====> HAPPY\n",
            "RT @taehyungpic: ðŸ“¸#TAEHYUNG  KR ðŸ›« USA\n",
            "\n",
            "have a safe flight â™¡\n",
            "FASHION ICON V https://t.co/cbmOlpnkfc =====> HAPPY\n",
            "RT @taehyungpic: ðŸ“¸#TAEHYUNG  KR ðŸ›« USA\n",
            "\n",
            "have a safe flight â™¡\n",
            "FASHION ICON V https://t.co/cbmOlpnkfc =====> HAPPY\n",
            "RT @UFOMJLeader: #AncientAliens Just said the Pyramid Text describes the Extraterrestrial gods as coming from Sirius and Orion. The Dogon câ€¦ =====> HAPPY\n",
            "RT @TaehyungUSA: Taehyung Trends USA [NEW]\n",
            "\n",
            "â— Baby Prince V | Entertainment \n",
            "\n",
            "Another cute nickname for FASHION ICON V given by the media hâ€¦ =====> HAPPY\n",
            "@bwhite_ee @pugpolitics1 @MattBraynard One might even argue that an insurrection is an act of war against the USA aâ€¦ https://t.co/janeh1DiQp =====> SAD\n",
            "Iâ€™d salute, blare â€œGOD BLESS THE USAâ€, all the decorum. A new holiday. A blending of 1776 &amp; 2021/2022/2023/2024. \n",
            "Aâ€¦ https://t.co/vKGXvEibxF =====> HAPPY\n",
            "RT @MollyJongFast: What if Facebook is a cancer just like big Tobacco? =====> HAPPY\n",
            "@nebegamonkai @MarkLevineNYC @RepRitchie @mvelaznyc Look @TTarasenkova\n",
            "Another USA dumb bot here ðŸ™„ðŸ™„\n",
            "They spread fasâ€¦ https://t.co/bHNfuyUSu1 =====> HAPPY\n",
            "@TreyYingst @ErinElmore More than 500,000 in the USA in less than a year.\n",
            "Due to ineptitude &amp; dismissiveness, becauâ€¦ https://t.co/V7C5W8Po6p =====> SAD\n",
            "RT @JohnFetterman: â€œPennsylvania wants this. Pennsylvaniaâ€™s farmers need this. Pennsylvaniaâ€™s veterans need this. Pennsylvanians that haveâ€¦ =====> SAD\n",
            "@TheEmilyDBaker @emme329 Iâ€™m not from USA so unfamiliar w/ lawsâ€¦ doesnâ€™t invoking the 5A automatically tell us &amp; poâ€¦ https://t.co/hG5hNaZb6V =====> SAD\n",
            "@derekmutuma @BoqorWiilBari @Malikbandz5 @MohamedAliUmar1 @citizentvkenya @YvonneOkwara U seem not to know ur own hâ€¦ https://t.co/CuETVNOVjv =====> SAD\n",
            "RT @catturd2: ðŸ˜‚ðŸ˜‚ðŸ˜‚ðŸ˜‚\n",
            "\n",
            "#CatturdsBirthday is the #2 trend in the USA =====> HAPPY\n",
            "RT @SAFoundationN: Highlights from #BuildingDreams #USAtour2021 where  #SAF reps @SAfridiOffical, @jk555squash &amp; @adnanactor along with #SAâ€¦ =====> HAPPY\n",
            "RT @NunesAlt: Dems who want to win elections please pay attention to this. =====> SAD\n",
            "@WhiteHouse @POTUS @HHSGov @SecBecerra Open usa open up your borders  to eu and uk families coming back to there faâ€¦ https://t.co/diJcCK3NwZ =====> SAD\n",
            "RT @TrumpsBlonde_1: Over 10,000 Haitians entering Texas, USA in the last 2 daysâ€¦\n",
            "\n",
            "how is this even possible?? https://t.co/2ocACpTVOs =====> SAD\n",
            "RT @accessmimi: Mariah Carey, Britney Spears, Selena Quintanilla, and Aaliyah are the ONLY artists this year to spend a week as the most-stâ€¦ =====> HAPPY\n",
            "Real time #gold price in your National Currency For #Android\n",
            "\n",
            "https://t.co/eBZXaJvz50\n",
            "\n",
            "#USA #NewZealand #WhiteOut =====> HAPPY\n"
          ]
        }
      ],
      "source": [
        "import tweepy\n",
        "from tweepy import Stream\n",
        "from tweepy.streaming import StreamListener\n",
        "from tweepy import OAuthHandler\n",
        "import socket\n",
        "import json\n",
        "class TweetsListener(StreamListener):\n",
        "    def on_data(self, data):\n",
        "        msg = json.loads(data)\n",
        "        try:\n",
        "            predict(msg['text'])\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "\n",
        "\n",
        "    def on_error(self, status):\n",
        "        print(status)\n",
        "        return True\n",
        "\n",
        "auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_secret)\n",
        "twitter_stream = Stream(auth, TweetsListener())\n",
        "twitter_stream.filter(track = [\"egypt\",\"usa\"], languages=[\"en\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "russian-rochester",
      "metadata": {
        "id": "russian-rochester"
      },
      "source": [
        "# SIMPLE WEB APP (Bonus Part)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "union-world",
      "metadata": {
        "id": "union-world"
      },
      "outputs": [],
      "source": [
        "import tweepy\n",
        "from tweepy import Stream\n",
        "from tweepy.streaming import StreamListener\n",
        "from tweepy import OAuthHandler\n",
        "import socket\n",
        "import json\n",
        "consumer_key='uDlVzQSgq99mRln8MjBPVYeNR'\n",
        "consumer_secret='2rZslo6UcO89CXtBJtwxhw4l4cgBVgmjiz9TFUDx4vUTXKYEEp'\n",
        "access_token ='1438092111409291266-FtQ6ayZ5VR7Zsdfyh0py3VPRtzUSmf'\n",
        "access_secret='qM2m1sJzBa34TfRHszXPyZeRrSbwBktw7F6fZeAVWFaUH'\n",
        "class TweetsListener(StreamListener):\n",
        "    def on_data(self, data):\n",
        "        msg = json.loads(data)\n",
        "        try:\n",
        "            tweet,feeling = predict(msg['text'])\n",
        "            put_table([['tweet', 'sentiment'],[put_text(str(tweet)), put_text(str(feeling))]])\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "\n",
        "\n",
        "    def on_error(self, status):\n",
        "        print(status)\n",
        "        return True\n",
        "\n",
        "auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_secret)\n",
        "twitter_stream = Stream(auth, TweetsListener())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dominican-footage",
      "metadata": {
        "id": "dominican-footage",
        "outputId": "f8f26dcf-1dac-483b-bc88-909058850dc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "no one makes me happy like ateez does =====> HAPPY\n",
            "RT @LucasTurnbloom: HOW TO CAT: â€œSpotâ€ \n",
            ".\n",
            "Happy #caturday everyone!\n",
            ".\n",
            "https://t.co/qG1IXo4wUe https://t.co/gPsbTYuxBE =====> HAPPY\n",
            "@TrustWallet Happy birthday trust wallet and twt thank you for the Best wallet =====> HAPPY\n",
            "RT @neiljedcastro: We all have our breaking points in this life. We all get tired of waiting and chasing for that dream to happen. We all gâ€¦ =====> HAPPY\n",
            "â™¡                                                       â™¡\n",
            "            put this on your profile\n",
            "            and whoâ€¦ https://t.co/QLE9chbD3x =====> HAPPY\n",
            "@tuechainz happy gday my boy ðŸ’ªðŸ¾ =====> HAPPY\n",
            "RT @Gatorcwboyfan: 5 ainâ€™t it, bottom line. We all wanted his patience to be rewarded. Fairytales donâ€™t always have a happy ending. =====> HAPPY\n",
            "RT @mygiorni: ðŸŽ¶ Happy Birthday Laboon ðŸŽ¶ \n",
            "\n",
            "#ONEPIECE https://t.co/RZ3OkPxvZP =====> HAPPY\n",
            "happy birthday to me im gonna eat king crab and drink g&amp;tâ€™s all night =====> HAPPY\n",
            "RT @razzparks: happy birthday @JawnRocha, an amazing photographer plus more!\n",
            "from all of us to you, have a good one â¤ï¸â­ï¸!! https://t.co/Pz1â€¦ =====> HAPPY\n",
            "RT @ChelseaFC: Happy Birthday, @cpulisic_10! ðŸ¥³ https://t.co/BG9tddm7M7 =====> HAPPY\n",
            "RT @_Pammy_DS_: I love people who are genuinely happy for other people's happiness. =====> HAPPY\n",
            "I don't often see these two specific Sonic shows merged together like this.\n",
            "\n",
            "Let's give it up for the characters frâ€¦ https://t.co/PF61fpnTVj =====> HAPPY\n",
            "Thank god most of these actual subhuman pieces of shit arenâ€™t in this country. =====> HAPPY\n",
            "RT @aura_draws: Happy belated birthday to our favorite Mondstadt alchemist, Albedo! âœ¨ðŸ”ï¸ðŸŽ‚\n",
            "\n",
            "#GenshinImpact #åŽŸç¥ž #Albedo #Klee https://t.co/eyFâ€¦ =====> HAPPY\n",
            "RT @SkySportsPL: \"It's such a great feeling - words can't even explain it!\" ðŸ¤©\n",
            "\n",
            "Leon Bailey was very happy with his 20-minute cameo in #AVFCâ€¦ =====> HAPPY\n",
            "RT @dagurlJT: One band one sound. ðŸ˜Œ =====> HAPPY\n",
            "RT @loey_exo7: Happy Birthday Papa Park! ðŸŽŠï¸\n",
            "\n",
            "#CHANYEOL #EXO https://t.co/ExX8wkxjyT =====> HAPPY\n",
            "RT @sane_kyle: Happy anniversary to @SupergiantGames' hit, Hades!\n",
            "Reposting this in celebration of this event! \n",
            "\n",
            "#hadesgame #zagreus #hadesâ€¦ =====> HAPPY\n",
            "RT @jayjayriv: happy hispanic heritage month https://t.co/4p1dNmUI8Z =====> HAPPY\n",
            "@piilliiii Happy birthday best girl ðŸ¤ðŸ¤ðŸ¤ðŸ¤ðŸ¤ðŸ¤ðŸ’—ðŸ’— =====> HAPPY\n",
            "Happy Birthday Castiel ðŸ’— =====> HAPPY\n",
            "RT @DanSchkade: ðŸ¦‡ @DialHForHagai and I pooled our resources (he wrote, I drew). Happy #BatmanDay to those who observe ðŸ¦‡ https://t.co/6MipqBâ€¦ =====> HAPPY\n",
            "@mfarrar13 Thanks for reaching out, Matt! We'd be happy to help you. Please DM us with the name. email and ZIP Codeâ€¦ https://t.co/BKGKToHS43 =====> HAPPY\n",
            "RT @marie_nassar: @semljnika Good morning dear Daria ðŸŒ¹ðŸ‚â˜•ï¸ðŸªðŸ™‹â€â™€ï¸ðŸ˜˜\n",
            "Have a happy Monday and a wonderful new week full of joy and happiness my sâ€¦ =====> HAPPY\n",
            "I didn't even consider that this many people would come to celebrate. To be fair I am a bit shocked, but I'm happy...â™ª =====> HAPPY\n",
            "RT @ZackSnyder: Happy Batman Day! It's the perfect day to run out and grab your copy of the ZSJL. #BatmanDay #ZackSnydersJusticeLeague \n",
            "\n",
            "htâ€¦ =====> HAPPY\n",
            "Liam retweeted this tweet! =====> HAPPY\n",
            "Happy National Dance Day 2 some real QUEENS @EmmaSlaterDance @atrebunskaya @BrittBStewart @CherylBurkeâ€¦ https://t.co/vZRzWcc3kK =====> HAPPY\n",
            "RT @ZackSnyder: Happy Batman Day! It's the perfect day to run out and grab your copy of the ZSJL. #BatmanDay #ZackSnydersJusticeLeague \n",
            "\n",
            "htâ€¦ =====> HAPPY\n",
            "RT @ndoup9: When junior khanye speaks we think he's crazy,  I'm happy Royal AM humiliated Baxter and he must leave with immediate effects hâ€¦ =====> HAPPY\n",
            "Omg yes, I did it in the morning. Lol. =====> HAPPY\n",
            "RT @taranooyen: This is the best example of parenting that Iâ€™ve ever read on Twitter. Parenting is wanting to make your child happy, make yâ€¦ =====> HAPPY\n",
            "RT @rue29Napa: Who else loves @napafarmersmkt ðŸ™‹ðŸ»â€â™€ï¸ So many new vendors at todayâ€™s Saturday market. Happy to see the Dahlia Farm from Petalâ€¦ =====> HAPPY\n",
            "RT @ZackSnyder: Happy Batman Day! It's the perfect day to run out and grab your copy of the ZSJL. #BatmanDay #ZackSnydersJusticeLeague \n",
            "\n",
            "htâ€¦ =====> HAPPY\n",
            "RT @Scotkraut: If the last 5 years have been positive in any way, then it was to clearly demonstrate the difference between Scotland and Enâ€¦ =====> HAPPY\n",
            "RANBOO SOUNDS SO HAPPY IM GONNA CRY :((( /POS =====> HAPPY\n",
            "I have never seen a happier person who goes in search for how to be a happy human being #mondaythoughts #ThinkBIGSundayWithMarsha =====> HAPPY\n",
            "RT @_wowser: Happy birthday to @HannahTelle, our Max Caulfield â¤ï¸ https://t.co/jo6xoEpERn =====> HAPPY\n",
            "im gonna rip my organs our he sounds so happy an d excited im gonan =====> HAPPY\n",
            "RT @TheOriginalCIR: me vs. animated me\n",
            "\n",
            "(happy #BIPOCvampday ðŸ¦‡ðŸ©¸) https://t.co/jHDPGF5PSr =====> HAPPY\n",
            "RT @Coolwednesdays_: Happy birthday Capone https://t.co/v6AONbG9z3 =====> HAPPY\n",
            "Lopes putting out classics every week!! ðŸ˜­ Damn Iâ€™m happy for the boys. Lopes up we win! =====> HAPPY\n",
            "RT @tshirtsunited: While we're all laughing at Pep's comments on city fans, city fans in general and memes about free tickets to see city iâ€¦ =====> HAPPY\n",
            "RT @kateschIoe: like he said ðŸ¤·ðŸ½â€â™€ï¸ https://t.co/fvNy43Gkc4 =====> HAPPY\n",
            "RT @darkseidxflame: Happy #BatmanDay lets appreciate Ben Afflecks Batman https://t.co/qJa5D73YR6 =====> HAPPY\n",
            "@TheJimCornette @StaceyCornette Happy Birthday =====> HAPPY\n",
            "Please visit our website for details around our plan as we approach Sept 20th. We are happy to host those of you thâ€¦ https://t.co/1awlP8AUNF =====> HAPPY\n",
            "Just Minted my First Ever #SolanaNFT ðŸ”¥ðŸ”¥ðŸ”¥. Listing soon on @SolanartNFT. I'm happy to be part of the @TheCavemenClubâ€¦ https://t.co/ZHsgQegFhW =====> HAPPY\n",
            "RT @C_Angermayer: \"Ultimately, I believe that #mentalhealth has 100% total addressable market because 100% of the people want to be healthyâ€¦ =====> HAPPY\n",
            "RT @C_Angermayer: \"Ultimately, I believe that #mentalhealth has 100% total addressable market because 100% of the people want to be healthyâ€¦ =====> HAPPY\n",
            "RT @ZackSnyder: Happy Batman Day! It's the perfect day to run out and grab your copy of the ZSJL. #BatmanDay #ZackSnydersJusticeLeague \n",
            "\n",
            "htâ€¦ =====> HAPPY\n",
            "RT @ZackSnyder: Happy Batman Day! It's the perfect day to run out and grab your copy of the ZSJL. #BatmanDay #ZackSnydersJusticeLeague \n",
            "\n",
            "htâ€¦ =====> HAPPY\n",
            "RT @ZackSnyder: Happy Batman Day! It's the perfect day to run out and grab your copy of the ZSJL. #BatmanDay #ZackSnydersJusticeLeague \n",
            "\n",
            "htâ€¦ =====> HAPPY\n",
            "@GeminiFlanaganC @ChrisEvans @ChrisEvansmylov @ChristEvans81 @chrisevansrare @softchrisdodger @cap_evans_â€¦ https://t.co/LBWhkMOmuj =====> HAPPY\n",
            "RT @n1010505: Social media is a trick used by people to be happy and  also show others that they are happy.\n",
            "\n",
            "Everybody search for happinessâ€¦ =====> HAPPY\n",
            "RT @Anitta: One year of \"Me Gusta\" and I'm so happy and proud of it â¤ï¸ @iamcardib @MYKETOWERS https://t.co/j2opDnu05W =====> HAPPY\n",
            "RT @bumplebeee: âšœï¸hii Iâ€™m sammie, Iâ€™m a black transmasc artist trying to make others happy with my art Ù©( á› )ÙˆIâ€™m getting so close to hittiâ€¦ =====> HAPPY\n",
            "RT @CynthiaNixon: Happy one year, my Mildred â¤ï¸  #Ratched\n",
            "\n",
            "@MsSarahPaulson @MrRPMurphy @RatchedNetflix https://t.co/xlAGX0T1At =====> HAPPY\n",
            "lock it off this game is cancelled =====> HAPPY\n",
            "What a Saturday ðŸ˜… =====> HAPPY\n",
            "RT @DanScavino: Happy Birthday @catturd2! \n",
            "#CatturdsBirthday https://t.co/hNNyVVgIBo =====> HAPPY\n",
            "âNononononono Its fine...I'll get it under control okay! Just need another...note from my therapist or somethingâžâ€¦ https://t.co/6jWAYkKsC2 =====> HAPPY\n"
          ]
        }
      ],
      "source": [
        "from pywebio.input import input, FLOAT\n",
        "from pywebio.output import put_text ,put_table \n",
        "def doit(word):\n",
        "    twitter_stream.filter(track = [str(word)], languages=[\"en\"])\n",
        "\n",
        "def bmi():\n",
        "    word = input(\"Enter one keyword: \")\n",
        "    doit(word)\n",
        "if __name__ == '__main__':\n",
        "    bmi()\n",
        "\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "skilled-bracket",
      "metadata": {
        "id": "skilled-bracket"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "great-stamp",
      "metadata": {
        "id": "great-stamp"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.11"
    },
    "colab": {
      "name": "Script.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
